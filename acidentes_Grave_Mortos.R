###############################################################
# SESS√ÉO 1 ‚Äî Configura√ß√£o inicial e bibliotecas
###############################################################

setwd("G:\\Meu Drive\\predicao-acidentes")
# working directory

#Bibliotecas
library(dplyr)
library(readxl)
library(expss)
library(Information) 
library(arules)
library(smbinning)
library(HH)
library(InformationValue) 
library(scorecard)
library(partykit)
library(CHAID)
library(gtools)
library(expss)
library(devtools)
library(Hmisc)


#install.packages("devtools")
#devtools::install_github("cran/InformationValue")


###############################################################
# SESS√ÉO 1.1 ‚Äî Importa√ß√£o da base e prepara√ß√£o inicial
###############################################################

# ******************************************
# METODOLOGIA INICIAL PARA MONTAR O MODELO #
# ******************************************

library(readxl)
options(scipen=999)

# Conectar o R diretamente ao Excel
# data <- read_excel("dados.xlsx",sheet="Plan1") 
# data<-as.data.frame(data)


# Conectar o R diretamente ao SQL Server
#install.packages("odbc")
#install.packages("DBI")
library(DBI)
library(odbc)

# Conectar
conex_SQL <- dbConnect(odbc(),
                 Driver = "SQL Server",
                 Server = "PAULO",
                 Database = "TCC_FIA_2",
                 Trusted_Connection = "True")

# Testar conex√£o
dbGetQuery(conex_SQL, "
    SELECT TABLE_NAME 
    FROM INFORMATION_SCHEMA.TABLES 
    WHERE TABLE_SCHEMA = 'dbo'
")

# Desconectar
# dbDisconnect(conex_SQL) 

# Puxar a tabela do SQL e salvar no objeto data -- 67.127 registros
data <- dbGetQuery(conex_SQL, "
    SELECT *
    FROM dbo.base_acidentes_BR116_SP
")


# EXPORTAR O .CSV, origem SQL SERVER para BACKUP Silver
# Avalair se precisa sobrepor. Se houver altera√ß√£o no SQL, exportar novamente.
# write.csv(data, "data/silver/data.csv", row.names = FALSE)

# rm(data)


###############################################
# 2. Padronizando as clases das vari√°veis
# IDENTIFICADORES (n√£o entram no modelo)
###############################################

summary(data)

for (col in names(data)) print(col)

vars_id <- c(
  "Num_Ocorrencia"   # identificador √∫nico do acidente
)

vars_tempo <- ("DataRef")

###############################################
# 2.1 VARI√ÅVEIS EXPLICATIVAS (X)
###############################################

# 2.1.1 Vari√°veis categ√≥ricas explicativas
vars_categoricas <- c(
  "Concessionaria",
  "Periodo",
  "Trecho",
  "Pista",
  "SentidoPadrao"
)

# 2.2.2 Vari√°veis num√©ricas explicativas (contagens)
vars_numericas <- c(
  "KmDecimal",
  "Automovel", "Bicicleta", "Caminhao", "Moto", "Onibus", "Outros", "Utilitario",
  "Ilesos", "Levemente_feridos", "Moderadamente_feridos",
  "Gravemente_feridos", "Mortos"
)

# 2.1.3 Vari√°veis bin√°rias explicativas (0/1)
vars_binarias <- c(
  "Automovel_bin", "Bicicleta_bin", "Caminhao_bin", "Moto_bin",
  "Onibus_bin", "Outros_bin", "Utilitario_bin",
  "Ilesos_bin", "Levemente_feridos_bin", "Moderadamente_feridos_bin",
  "Gravemente_feridos_bin", "Mortos_bin"
)


###############################################
# 2.2 POSS√çVEIS TARGETS (Y)
###############################################

# Estudo univariado, pontual
summary(data$TipoDeOcorrenciaPadrao)
cro(data$TipoDeOcorrenciaPadrao)

vars_target <- c(
  "TipoDeOcorrenciaPadrao",     # tipo de ocorr√™ncia (multiclasse)
  "Vitimas",                   # acidente teve v√≠timas (qualquer gravidade)
  "Gravemente_feridos_Mortos" # acidente grave (feridos graves ou mortos)
)

###############################################
# 2.3 TRATAMENTO DE VALORES VAZIOS
#    "" ‚Üí NA (decis√£o metodol√≥gica documentada)
# regress√£o log√≠stica n√£o aceita strings vazias
# √°rvores de decis√£o tratam vazio como categoria v√°lida, o que distorce tudo
# modelos preditivos ficam enviesados
# m√©tricas ficam erradas
# vari√°veis bin√°rias ficam quebradas
# Transformar vazios em NA √© obrigat√≥rio antes de seguir.
###############################################

# Avalia√ß√£o
colSums(is.na(data))
colSums(data == "")

# Substituir todos os vazios por NA
data[data == ""] <- NA

# Teste, para ver os NA reais.
colSums(is.na(data))

###############################################
# 2.4 CONVERS√ÉO DE TIPOS
###############################################

# 2.4.1 Converter vari√°veis num√©ricas
data[vars_numericas] <- lapply(data[vars_numericas], as.numeric)

# 2.4.2 Converter vari√°veis bin√°rias (0/1)
data[vars_binarias] <- lapply(data[vars_binarias], as.numeric)

# 2.4.3 Converter vari√°veis categ√≥ricas
data[vars_categoricas] <- lapply(data[vars_categoricas], as.factor)

# TipoDeOcorrenciaPadrao √© categ√≥rico (multiclasse)
data$TipoDeOcorrenciaPadrao <- as.factor(data$TipoDeOcorrenciaPadrao)

# 2.4.4 Converter data
data$DataRef <- as.Date(data$DataRef)
# ou
data[vars_tempo] <- lapply(data[vars_tempo], as.Date)

# 2.4.5 Converter targets
# Vitimas e Gravemente_feridos_Mortos s√£o bin√°rios
data$Vitimas <- as.numeric(data$Vitimas)
data$Gravemente_feridos_Mortos <- as.numeric(data$Gravemente_feridos_Mortos)


###############################################################
# SESS√ÉO 3 ‚Äî Avalia√ß√£o das TARGETS
# a target define o problema
###############################################################
str(data[vars_target]) 

cro(data$Vitimas)
cro_cpct(data$Vitimas)

cro(data$Gravemente_feridos_Mortos)
cro_cpct(data$Gravemente_feridos_Mortos)

cro(data$TipoDeOcorrenciaPadrao)
cro_cpct(data$TipoDeOcorrenciaPadrao)


# Vitimas √© ampla demais e mistura leve, moderado, grave e morte.
# TipoDeOcorrenciaPadrao s√≥ separa ‚Äúcom v√≠tima‚Äù e ‚Äúsem v√≠tima‚Äù, n√£o mede severidade.
# Gravemente_feridos_Mortos foca exatamente nos casos severos e representa 5,2% dos acidentes, refletindo melhor a realidade que queremos modelar.
#
# Conclus√£o: a target mais coerente e robusta para prever severidade √© Gravemente_feridos_Mortos.

vars_target <- setdiff(vars_target, "Vitimas")
vars_target <- setdiff(vars_target, "TipoDeOcorrenciaPadrao")
#
vars_target
str(data[vars_target]) 
# TARGET ESCOLHIDA
# Gravemente_feridos_Mortos 

###############################################################
# SESS√ÉO 4 ‚Äî An√°lise Explorat√≥ria Univariada (AED) e Bivariada
# Em an√°lise univariada e bivariada ‚Üí manter NA √© o certo
# objetivo: entender o fen√¥meno # Aqui NA √© informa√ß√£o
###############################################################

summary(data)

library(skimr)
skim (data)

names(data)

#Quantitativa
cro(data$Automovel) # o cro() oculta os NA por padr√£o.

# Tabela de frequencias
for (vars_numericas_analise in vars_numericas) {
  cat("\n\n==============================\n")
  cat("Frequ√™ncia de:", vars_numericas_analise, "\n")
  cat("==============================\n")
  print(table(data[[vars_numericas_analise]], useNA = "ifany"))
}


#Qualitativas / Categ√≥ricas

str(data[vars_categoricas])

cro_cpct(data$Concessionaria) # Desbalanceamento extremo O modelo n√£o aprende nada sobre a categoria minorit√°ria, por isso n√£o vamos usar no modelo
cro_cpct(data$Trecho) # O Trecho √© extremamente desbalanceado e, portanto, n√£o tem poder explicativo para o modelo.

vars_categoricas <- setdiff(vars_categoricas, "Concessionaria") # removido, mas mantido na base original para efeito de controle visual do dashboard
vars_categoricas <- setdiff(vars_categoricas, "Trecho") # removido

cro_cpct(data$Pista) # Como filtramos da base original apenas a BR‚Äë116/SP, o campo perdeu variabilidade
vars_categoricas <- setdiff(vars_categoricas, "Pista")

cro_cpct(data$SentidoPadrao) # O campo n√£o √© confi√°vel, mesmo ap√≥s tratamento continua (50/50).
vars_categoricas <- setdiff(vars_categoricas, "SentidoPadrao")

cro_cpct(data$Periodo) # tem distribui√ß√£o saud√°vel ou seja Variabilidade boa, N√£o √© colinear

#Bin√°rias
str(data[vars_binarias])

cro_cpct(data$Automovel_bin) # Boa, tem variabilidade

cro_cpct(data$Bicicleta_bin) # Ruim, Vari√°vel extremamente rara, Quase n√£o aparece na base
vars_binarias <- setdiff(vars_binarias, "Bicicleta_bin")

cro_cpct(data$Caminhao_bin) # Boa, tem variabilidade

cro_cpct(data$Moto_bin) # Boa, tem variabilidade

cro_cpct(data$Onibus_bin) # ‚â• 5% ‚Üí vari√°vel aceit√°vel, n√£o √© rara demais  

cro_cpct(data$Outros_bin) # Boa, tem variabilidade

cro_cpct(data$Utilitario_bin) # ‚â• 5% ‚Üí vari√°vel aceit√°vel, n√£o √© rara demais 

cro_cpct(data$Ilesos_bin) # ‚â• 5% ‚Üí vari√°vel aceit√°vel, n√£o √© rara demais 

cro_cpct(data$Levemente_feridos_bin) # Boa, tem variabilidade
vars_binarias <- setdiff(vars_binarias, "Levemente_feridos_bin") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o

cro_cpct(data$Moderadamente_feridos_bin) # Boa, tem variabilidade
vars_binarias <- setdiff(vars_binarias, "Moderadamente_feridos_bin") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o

cro_cpct(data$Gravemente_feridos_bin) # Fraca e usei para criar uma possivel target,n√£o deve entrar como preditora
vars_binarias <- setdiff(vars_binarias, "Gravemente_feridos_bin") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o

cro_cpct(data$Mortos_bin) # Fraca e usei para criar uma possivel target,n√£o deve entrar como preditora
vars_binarias <- setdiff(vars_binarias, "Mortos_bin") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o

vars_binarias

###############################################################
# SESS√ÉO 5 ‚Äî Categoriza√ß√£o de vari√°veis num√©ricas
# An√°lise Explorat√≥ria Univariada (AED) e Bivariada
###############################################################
str(data[vars_numericas]) 

str(data$Automovel)
summary(data$Automovel)

# Discretiza√ß√£o de Variavel com NA, 
qs_Automovel <- quantile(data$Automovel, probs = seq(0, 1, 0.25), na.rm = TRUE)
qs_Automovel <- unique(qs_Automovel)  # evita quantis repetidos
data$Automovel_cat <- cut(data$Automovel, breaks = qs_Automovel, include.lowest = TRUE)
rm(qs_Automovel)

sum(is.na(data$Automovel))
cro_cpct(data$Automovel_cat)
table(data$Automovel, data$Automovel_cat)
table(data$Automovel_cat, data$Gravemente_feridos_Mortos)

table(data$Automovel, data$Gravemente_feridos_Mortos)

sum(is.na(data$Automovel))
sum(is.na(data$Automovel_cat))

# Automovel √© uma vari√°vel num√©rica com informa√ß√£o rica.
# Automovel_cat destr√≥i granularidade

# Removendo variaveis que respondem como Target ou possuem rela√ß√£o direta com a Target escolhida.
str(data[vars_numericas]) 

vars_numericas <- setdiff(vars_numericas, "Ilesos") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o
vars_numericas <- setdiff(vars_numericas, "Levemente_feridos")
vars_numericas <- setdiff(vars_numericas, "Moderadamente_feridos")
vars_numericas <- setdiff(vars_numericas, "Gravemente_feridos")
vars_numericas <- setdiff(vars_numericas, "Mortos")

# Avaliando demais vari√°veis numericas
str(data[vars_numericas]) 

# Distribui√ß√£o regular - vamos estudar no modelo - Removemos a vers√£o bin, vamos manter esta
table(data$Bicicleta, data$Gravemente_feridos_Mortos)

# Boa distribui√ß√£o, vamos manter esta
table(data$Caminhao, data$Gravemente_feridos_Mortos)

# Boa distribui√ß√£o, vamos manter esta
table(data$Moto, data$Gravemente_feridos_Mortos)

# Distribui√ß√£o regular - vamos estudar no modelo, vamos manter esta
table(data$Onibus, data$Gravemente_feridos_Mortos)

# Boa distribui√ß√£o, vamos manter esta
table(data$Outros, data$Gravemente_feridos_Mortos)

# N√£o muito Boa distribui√ß√£o, vamos manter esta para testar adiante
table(data$Utilitario, data$Gravemente_feridos_Mortos)

###############################################################
# SESS√ÉO 6 ‚Äî Optimal Binning : binning supervisionado
# binning supervisionado s√≥ para vari√°veis num√©ricas cont√≠nuas
# At√© aproximadamente 10 valores distintos (decimal ou inteiro)
###############################################################
str(data[vars_numericas]) 

library(smbinning)


# Para analise individual
KmDecimal_optbin<-smbinning(df=data,y="Gravemente_feridos_Mortos",x="KmDecimal",p=0.05) 
KmDecimal_optbin
KmDecimal_optbin$iv
KmDecimal_optbin$ivtable  
#
# Adicionando na base
data<-smbinning.gen(data,KmDecimal_optbin, chrname="KmDecimal_optbin_cat")

# CRIANDO uma nova variavel binning, n√£o ficamos coerentes com a realidade
# O que seria de utilidade prever Y at√© ante de X Km e ap√≥s de X Km, neste caso 97 Km
sum(is.na(data$KmDecimal_optbin_cat))
table(data$KmDecimal_optbin_cat, data$Gravemente_feridos_Mortos)
cro_cpct(data$KmDecimal_optbin_cat)
summary(data$KmDecimal)


# KmDecimal √© uma vari√°vel espacial, n√£o uma vari√°vel preditiva comum
summary(data$KmDecimal)
table(data$KmDecimal, data$Gravemente_feridos_Mortos)

# O nome t√©cnico desta opera√ß√£o √© Binning Manual
#### Arbitrei em 11 faixas para ficar mais pr√≥ximo da realidade ############
# A categoria (200,250] tinha 34,1% dos casos ‚Äî um monstr√£o desbalanceado.
# Agora, (200,225] ‚Üí 25,7% e (225,250] ‚Üí 8,4%, melhora a sensibilidade da regress√£o e da √°rvore e evita que uma categoria gigante ‚Äúengula‚Äù o efeito das outras
data$Km_cat <- cut(
  data$KmDecimal,
  breaks = c(0, 50, 100, 150, 200, 225, 250, 300, 350, 400, 450, 500, 600),
  include.lowest = TRUE
)
table(data$Km_cat, data$Gravemente_feridos_Mortos)
cro_cpct(data$Km_cat)
summary(data$Km_cat)

# DE 0 a 250 km concentra praticamente 80% dos acidentes # A rodovia √© ‚Äúdensa‚Äù at√© 250 km e ‚Äúrala‚Äù depois disso.
# Criar mais faixas abaixo de 250 km e manter faixas maiores acima disso.
data$Km_cat <- cut(
  data$KmDecimal,
  breaks = c(0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 300, 400, 500, 600),
  include.lowest = TRUE
)
# A probabilidade de 1 sobre 0 nessa faixa  "(200,225] 10442 515" √© similar √†s faixas vizinhas, A faixa √© grande, mas est√°vel
cro_cpct(data$Km_cat)
table(data$Km_cat, data$Gravemente_feridos_Mortos)
summary(data$Km_cat)



vars_categoricas <- c(vars_categoricas, "Km_cat")
vars_categoricas



###############################################################
# SESS√ÉO 7 ‚Äî Cria√ß√£o de vari√°veis derivadas
###############################################################
dim(data)
head(data)
str(data)
nrow(data)



data$Onibus_Caminhao_Bin <- ifelse(data$Onibus_bin==1 | data$Caminhao_bin == 1, 1, 0)
table(data$Onibus_Caminhao_Bin, data$Gravemente_feridos_Mortos)
cro_cpct(data$Onibus_Caminhao_Bin)
summary(data$Onibus_Caminhao_Bin)

vars_binarias <- c(vars_binarias, "Onibus_Caminhao_Bin")
vars_binarias

###############################################################
# SESS√ÉO 8 ‚Äî Convers√£o de vari√°veis para modelagem
# Transformar vari√°veis que s√£o categorias (e n√£o n√∫meros cont√≠nuos) em fatores, para que:
# a regress√£o log√≠stica trate como categorias, a CHAID funcione corretamente, o R n√£o interprete n√∫meros como valores cont√≠nuos
###############################################################

str(data)
library(dplyr)

# Transformar todas as vari√°veis categ√≥ricas em factor
data[vars_categoricas] <- lapply(data[vars_categoricas], as.factor)

# Transformar todas as vari√°veis bin√°rias em factor
data[vars_binarias] <- lapply(data[vars_binarias], as.factor)

# Vari√°veis num√©ricas (revis√£o)
data[vars_numericas] <- lapply(data[vars_numericas], as.numeric)


###############################################################
# SESS√ÉO 8.1 ‚Äî Transformas TARGET em factor 
# (regress√£o aceita target n√∫merico), mas vamos simplificar e garantir quando factor
# Transformamos o target em fator para que o modelo trate como vari√°vel categ√≥rica (0 e 1)
###############################################################

# Transformar a target em factor
data[vars_target] <- lapply(data[vars_target], as.factor)
# OU
data$Gravemente_feridos_Mortos <- as.factor(data$Gravemente_feridos_Mortos)

# Definimos o n√≠vel "0" como refer√™ncia, garantindo que o modelo estime P(Y = 1),
# ou seja, a probabilidade de ocorrer um acidente grave ou com morte
data$Gravemente_feridos_Mortos <- relevel(data$Gravemente_feridos_Mortos, ref = "0")
#Validar o relevel
levels(data$Gravemente_feridos_Mortos)
# Retornar -> [1] "0" "1"
# ‚Äú0‚Äù √© o n√≠vel de refer√™ncia
# ‚Äú1‚Äù √© o evento modelado


# ---------------------------------------------------------------
# Quando usar a target como NUM√âRICA (0/1) vs FACTOR
#
# M√©todos que exigem target NUM√âRICA (0/1):
# - IV / WOE
# - Regress√£o log√≠stica
# - XGBoost / LightGBM (bin√°rio)
# - M√©tricas de performance (AUC, KS, Lift, LogLoss, Sensibilidade, etc.)
#
# M√©todos que exigem target FACTOR:
# - √Årvores de decis√£o (rpart, C5.0, party)
# - Random Forest (classifica√ß√£o)
# - SVM / kNN / Naive Bayes
#
# Resumo:
# Use target NUM√âRICA para c√°lculos estat√≠sticos e modelos baseados em probabilidade.
# Use target FACTOR para modelos de classifica√ß√£o baseados em classes.
# ---------------------------------------------------------------


###############################################################
# SESS√ÉO 9 ‚Äî Information Value (IV)
# CRIAR base para MODELO
# -------------------------------------------------------------
# Tabela de Interpreta√ß√£o do Information Value (IV)
#
# IV < 0.02        -> Sem poder preditivo
# 0.02 ‚Äì 0.10      -> Baixo poder preditivo
# 0.10 ‚Äì 0.30      -> M√©dio poder preditivo
# 0.30 ‚Äì 0.50      -> Forte poder preditivo
# IV > 0.50        -> Suspeito (pode indicar leakage)
# -------------------------------------------------------------
###############################################################

library(Information)

vars_modelagem <- c(
  vars_tempo,
  vars_numericas,
  vars_categoricas,
  vars_binarias,
  vars_target
)
# Criar o data frame final de modelagem
base <- data[, vars_modelagem]

# Removendo registro quando target = NA
# O target tem valores NA na base
sum(is.na(base$Gravemente_feridos_Mortos))/nrow(base)
# 36,9% da base est√° com o target NA
nrow(base)-sum(is.na(base$Gravemente_feridos_Mortos))
# A base sem NA dever√° contar 42303 registros

# remover apenas os registros com NA no target
base <- base[!is.na(base$Gravemente_feridos_Mortos), ]
cro_cpct(base$Gravemente_feridos_Mortos)
summary(base$Gravemente_feridos_Mortos)
nrow(base)
# 5,25% t√™m v√≠tima grave e/ou morta
# Ou seja, seu target √© fortemente desbalanceado, o que √© absolutamente normal em modelos de severidade.
# base agora est√° pronta para modelagem supervisionada.

# Transformar a vari√°vel target bin√°ria 0/1 de factor para num√©rica,
# para aplicar c√°lculos (IV), regress√£o glm() e √°rvore CHAID
base$Gravemente_feridos_Mortos <- as.numeric(as.character(base$Gravemente_feridos_Mortos))
class(base$Gravemente_feridos_Mortos)
cro_cpct(base$Gravemente_feridos_Mortos)

# IV
IV <- create_infotables(data = base, y = "Gravemente_feridos_Mortos")
IV$Summary



# Vari√°veis de leakage devem ser removidas SEMPRE, independentemente do IV
# Deixamos escapar nas analises anteriores
# s√£o derivadas do pr√≥prio target ou cont√™m informa√ß√£o direta sobre ele.
# Remover vari√°veis que s√£o efeitos do acidente, n√£o causas.
base$Ilesos_bin         <- NULL
vars_binarias <- vars_binarias[vars_binarias != "Ilesos_bin"]
vars_binarias

# Baixo poder preditivo ou sem poder preditivo IV <0.10
base$KmDecimal      <- NULL                    # IV = 0.03429499
base$Automovel_bin      <- NULL   # 0.09476693


# Onibus e Caminhao
base$Onibus     <- NULL
base$Caminhao    <- NULL
# Removemos porque Onibus e Caminho explicam bem e ficamos com a vers√£o bin√°ria delas

# Variaveis que a a nova variavel generica binaria teve o IV igual, ent√£o deixamos a binaria e removemos a numerica
base$Moto     <- NULL
base$Outros      <- NULL
base$Utilitario  <- NULL

# Automovel IV de 0.19111147, explica melhor o negocio e √© numerica serve tanto para regress√£o quanto para a arvore
# Automovel tem somente 13 valores de 0 at√© 12
table(base$Automovel, base$Gravemente_feridos_Mortos)


# CRIAR VARIAVEIS PERIODICAS
# Criar M√™s (01 a 12)
base$Mes <- format(base$DataRef, "%m")

# Criar Dia da Semana
base$DiaSemana <- weekdays(base$DataRef)

# Padronizar nomes (Ajuda no CHAID e regress√£o)
base$DiaSemana <- factor(base$DiaSemana,
                         levels = c("segunda-feira","ter√ßa-feira","quarta-feira",
                                    "quinta-feira","sexta-feira","s√°bado","domingo"))


# Avaliar IV
IV <- create_infotables(data = base, y = "Gravemente_feridos_Mortos")
IV$Summary


# Excluir variaveis periodicas que nao tiveram bom IV e DataRef
base$DataRef   <- NULL
base$Mes     <- NULL
base$DiaSemana      <- NULL


# Onibus_Caminhao_Bin IV 2.30202564, Suspeito e temos a orginais Onibus e Caminhao , vamos remove-la
base$Onibus_Caminhao_Bin      <- NULL

# Avaliar IV
IV <- create_infotables(data = base, y = "Gravemente_feridos_Mortos")
IV$Summary
# Tabela IV
dataIV <- IV$Summary
dataIV$Classif_IV <- ifelse(dataIV$IV <= 0.02, "Fraquissimo",
                            ifelse(dataIV$IV <= 0.1 ,"Fraco",
                                   ifelse(dataIV$IV <= 0.3 ,"M√©dia",
                                          ifelse(dataIV$IV <= 0.5 ,"Forte",
                                                 "Suspeita"))))
dataIV




###############################################################
# SESS√ÉO 10 ‚Äî Organiza√ß√£o final das vari√°veis
# Se necess√°rio
###############################################################

# names(base)
# base <- base[, c("Periodo",
#                  "Automovel",
#                  "Caminhao_bin", "Moto_bin", "Onibus_bin", "Utilitario_bin",
#                  "Bicicleta_bin", "Outros_bin",
#                  "Km_cat",
#                  "Gravemente_feridos_Mortos")]
# names(base)
# str(base)


###############################################################
# SESS√ÉO 11 ‚Äî Divis√£o Treino/Teste
# Sempre avaliar Tratar NAs nas vari√°veis do modelo, verificar se antecipa nesta etapa.
# Para modelagem ‚Üí remover NA apenas nas vari√°veis do modelo √© o certo
# objetivo: ajustar um modelo matem√°tico; NA atrapalha
###############################################################

# Verificar NAs no treino e teste
colSums(is.na(base))

# Criar a lista de vari√°veis que devem estar sem NA
vars_modelo_Sem_NA <- c( "Automovel", "Bicicleta", "Caminhao_bin", "Moto_bin", 
                         "Onibus_bin", "Outros_bin", "Utilitario_bin", "Periodo", 
                         "Km_cat", "Gravemente_feridos_Mortos" )

# Remover todas as linhas com NA nessas vari√°veis
base_limpa <- base[complete.cases(base[vars_modelo_Sem_NA]), ]

# EXPORTAR O .CSV, base_limpa para simular produ√ß√£o MLOps
# write.csv(base_limpa, "data/prepared/base_limpa_v1.csv", row.names = FALSE)



# Fixamos a semente para garantir reprodutibilidade.
# Assim, sempre que rodarmos o c√≥digo, a mesma amostra ser√° selecionada.
set.seed(42)

# Selecionamos aleatoriamente 80% das linhas da base_limpa para compor o conjunto de treino.
amostra <- sort(sample(nrow(base_limpa), nrow(base_limpa) * 0.80))

# Conjunto de treino: usado para ajustar (treinar) os modelos.
treino <- base_limpa[amostra, ]
# Conjunto de teste: usado para avaliar o desempenho do modelo em dados novos.
teste <- base_limpa[-amostra, ]


###############################################################
# SESS√ÉO 12 ‚Äî Regress√£o Log√≠stica
###############################################################

dataIV

# Aplicar modelagem
modelo <- glm(Gravemente_feridos_Mortos ~    
                Periodo+
                Automovel+Bicicleta+
                Caminhao_bin+Moto_bin+Onibus_bin+Outros_bin+Utilitario_bin+
                Km_cat,
              family=binomial(link='logit'),
              data=treino)
summary(modelo)
# AIC Akaike Information Criterion / Crit√©rio de Informa√ß√£o de Akaike
# Mede o equil√≠brio entre o qu√£o bem o modelo se ajusta aos dados (qualidade do ajuste) e o quanto ele √© simples (penaliza modelos com muitas vari√°veis)
# AIC DO MODELO: 8967.9
# AIC menor ‚Üí modelo melhor
# AIC maior ‚Üí modelo pior

# VARIAVEIS EM ALERTA:

### Caminhao_bin p-valor ruim e IV √≥timo
table(treino$Caminhao_bin)
prop.table(table(treino$Caminhao_bin))
# IV 2.44493864 suspeita
# p-valor 0.6873 alto
# VIF excelente

### Onibus_bin p-valor ruim e IV m√©dio
table(treino$Onibus_bin)
prop.table(table(treino$Onibus_bin))
# IV 0.16749755 M√©dia
# p-valor 0.3956 alto
# VIF excelente

### Utilitario_bin p-valor ruim e IV √≥timo
table(treino$Utilitario_bin)
prop.table(table(treino$Utilitario_bin))
# IV 0.15257725 m√©dio, O IV n√£o √© forte o suficiente para justificar manter.
# p-valor  0.3514  alto
# VIF excelente

### Km_cat
# Variavel de qualidade do entendimento do neg√≥cio
# IV Fraco
# VIF excelente
# o modelo precisa explicar risco por dist√¢ncia ‚Üí manter. porque se nao se torna irrelevante


# Km_cat: manter, pois √© vari√°vel central para explicar risco por dist√¢ncia.
# Caminhao_bin e Onibus_bin: manter, pois representa um tipo de ve√≠culo cr√≠tico na severidade.
# Utilitario_bin: remover, pois tem baixo impacto e n√£o √© essencial ao modelo.

# Frequ√™ncia da vari√°vel
# Se for rara ‚Üí remover ou agrupar.
#
# VIF (colinearidade) - alto ‚Üí remover
#
# Impacto no desempenho (AIC/AUC)
# Se o modelo piora sem ela ‚Üí manter
# Se nada muda ‚Üí remover
#
# Na regress√£o log√≠stica 
# Avaliar Estimate (coeficiente) ‚Üí interpreta√ß√£o do efeito no risco

###############################################################
# SESS√ÉO 13 ‚Äî VIF
# VIF = Variance Inflation Factor  
# √â um indicador que mostra quanto a vari√¢ncia do coeficiente de uma vari√°vel est√° sendo inflada por causa da multicolinearidade.
# VIF mede se uma vari√°vel est√° ‚Äúbrigando‚Äù com outra dentro do modelo.
# VIF entre 1 e 2 Excelente, sem colinearidade
# VIF < 5 ‚Üí seguro
# VIF entre 5 e 10 ‚Üí aten√ß√£o
# VIF > 10 ‚Üí problema s√©rio
###############################################################


library(HH)
vif(modelo)

# O modelo est√° coerente com a realidade operacional
# Usar a coluna: GVIF^(1/(2*Df))
# Todos VIF excelentes: N√£o existe colinearidade relevante


###############################################################
# SESS√ÉO 14 ‚Äî Ajustamento do Modelo / Se necess√°rio
###############################################################


# Aplicar modelagem
# modelo <- glm(Gravemente_feridos_Mortos ~    
#                 Periodo+
#                 Automovel+Bicicleta+
#                 Caminhao_bin+Moto_bin+Onibus_bin+Outros_bin+
#                 Km_cat,
#               family=binomial(link='logit'),
#               data=treino)
# summary(modelo)
# Remove Utilitario_bin
# AIC DO MODELO: 9145.3
# AIC: 9145.3, manteve o mesmo valor - Utilitario_bin realmente n√£o contribu√≠a com nada
# O modelo ficou mais simples
# N√£o perdeu qualidade (AIC igual)


###############################################################
# SESS√ÉO 15 ‚Äî KS (Kolmogorov-Smirnov), AUC e ROC
# KS: 0.00‚Äì0.20 muito fraco; 0.20‚Äì0.30 fraco; 0.30‚Äì0.40 razo√°vel; 0.40‚Äì0.50 bom; >0.50 excelente.
# AUC: 0.50 aleat√≥rio; 0.50‚Äì0.60 fraco; 0.60‚Äì0.70 razo√°vel; 0.70‚Äì0.80 bom; 0.80‚Äì0.90 muito bom; >0.90 suspeito.
# ROC: Interpreta√ß√£o visual
# Curva pr√≥xima da diagonal = fraco; levemente acima = razo√°vel;
# bem arqueada = bom; muito arqueada = excelente; quase perfeita = suspeito (overfitting).

###############################################################

library(pROC)

# ADICIONAR O CAMPO DA PROBABILIDADE ao treino
treino$probabilidade = predict(modelo,treino, type = "response")

ks_stat(actuals=treino$Gravemente_feridos_Mortos, predictedScores=treino$probabilidade)
# 0.3389 razo√°vel, mas esperado devido ao target raro; modelo est√°vel.

roc_obj <- pROC::roc(treino$Gravemente_feridos_Mortos, treino$probabilidade)
pROC::auc(roc_obj)
# Area under the curve: 0.7313 bom

plot(roc_obj, col = "blue", lwd = 2)
# Devido o AUC, A curva ROC deve estar bem arqueada, mas n√£o perfeita.


# ADICIONAR O CAMPO DA PROBABILIDADE ao teste
teste$probabilidade = predict(modelo,teste, type = "response")

ks_stat(actuals=teste$Gravemente_feridos_Mortos, predictedScores=teste$probabilidade)
# 0.3982 razo√°vel, mas esperado devido ao target raro; modelo est√°vel.

roc_obj_teste <- pROC::roc(teste$Gravemente_feridos_Mortos, teste$probabilidade)
pROC::auc(roc_obj_teste)
# Area under the curve: 0.7494 bom

plot(roc_obj_teste, col = "blue", lwd = 2)
# Devido o AUC, A curva ROC deve estar bem arqueada, mas n√£o perfeita.

# Area under the curve: 0.7225 bom; desempenho consistente com o de treino e sem overfitting.
# Sobre o gr√°fico, Quanto mais a curva se aproxima do canto superior esquerdo, melhor
# Esse canto representa:Sensibilidade = 1, Falso positivo = 0 - Ou seja: modelo perfeito.


# Os resultados no teste est√£o totalmente coerentes com o que vimos no treino
# AUC: A diferen√ßa √© pequena ‚Üí n√£o h√° overfitting


###############################################################
# SESS√ÉO 16 ‚Äî Ponto de Corte
###############################################################

library(cutpointr)

# AVALAIR/revisar SE EXISTE NA's na base (n√£o deve ter)
colSums(is.na(treino[, c("probabilidade", "Gravemente_feridos_Mortos")]))
#  NA acontece quando o predict() n√£o consegue calcular a probabilidade para algumas linhas do treino, porque Existem valores NA nas vari√°veis explicativas usadas no modelo.

# Se NAs surgiram depois do modelo estar pronto, Isso n√£o afeta o modelo, s√≥ afeta a previs√£o dessas linhas.
# E o cutpointr n√£o aceita NA, por isso deu erro. Remover NAs agora n√£o invalida nada

# Se necess√°rio Mant√©m somente as linhas onde nenhuma dessas duas colunas tem NA
# J√° eliminamos linhas com NA devido variaveis explicativas para criar a base de treino e teste
# treino2 <- treino[complete.cases(treino[, c("probabilidade", "Gravemente_feridos_Mortos")]), ]
# Confere se ainda existe NA
# colSums(is.na(treino2[, c("probabilidade", "Gravemente_feridos_Mortos")]))


# Equilibra sensibilidade e especificidade.
ponto <- cutpointr(treino, probabilidade, Gravemente_feridos_Mortos,
                   method = minimize_metric, metric = abs_d_sens_spec)
summary(ponto)
# Obter ponto de cort cuttoff: 0.0327  Esse cutoff √© baixo, porque seu modelo gera probabilidades pequenas (target raro)
# optimal_cutpoint = 0.0327 
# sensibilidade = 0.6637 # acerta 66.4% dos casos graves (sensibilidade).
# especificidade = 0.6636 
# Esse √© o cutoff mais adequado para modelos de severidade, onde FN √© caro.


# Accuracy engana quando a classe 1 √© rara. Descartado
ponto2 <- cutpointr(treino, probabilidade, Gravemente_feridos_Mortos,
                   method = maximize_metric, metric = accuracy)
summary(ponto2)
# Obter ponto de cort cuttoff: Inf    # accuracy d√° cutoff absurdo
# optimal_cutpoint = Inf   
# sensibilidade = 0
# especificidade = 1
# acc = 0.9665 # Acur√°cia fica alta porque 97% dos casos s√£o 0.


# Cutoff pelo F1 (classe rara ‚Üí muito √∫til)
# Conservador N√£o recomendado para severidade.
ponto_f1 <- cutpointr(treino, probabilidade,Gravemente_feridos_Mortos,
                      method = maximize_metric, metric = F1_score)
summary(ponto_f1)
# optimal_cutpoint: 0.0893


# Cutoff pelo KS (maximiza separa√ß√£o)
# O cutoff que maximiza Youden √© o cutoff que maximiza o KS
ponto_ks <- cutpointr(treino, probabilidade, Gravemente_feridos_Mortos,
                      method = maximize_metric, metric = youden)
summary(ponto_ks)
# optimal_cutpoint:0.0306

# Qual cutoff √© o melhor para o seu modelo?
#   Seu problema √© severidade de acidentes, onde:   
#   FN = deixar de identificar um caso grave# 
#   FP = classificar como grave quando n√£o √©
# 
# Em modelos de severidade: ‚úî FN √© muito mais caro que FP
# 1¬∫ lugar: KS (0.0306)
# Maior sensibilidade # Menor FN # Melhor separa√ß√£o estat√≠stica # Ideal para risco/severidade


# INCLUIR A PROBABILIDADE DO PONTO DE CORTE ESCOLHIDO NO TESTE (SOBREPOR)
teste$probabilidade <- predict(modelo, teste, type = "response")

teste$probb_cat <- ifelse(teste$probabilidade>0.0306,1,0)
# Gerar a matriz cruzada (confus√£o)
cro(teste$Gravemente_feridos_Mortos, teste$probb_cat)



###############################################################
# SESS√ÉO 16 ‚Äî M√©tricas de desempenho do TESTE
###############################################################

# matriz cruzada (confus√£o)
teste$Real <- teste$Gravemente_feridos_Mortos
teste$Predito <- teste$probb_cat
cro(teste$Real, teste$Predito)
# OU
cro(teste$Gravemente_feridos_Mortos, teste$probb_cat)

# Valores da matriz de confus√£o
TP <- 251
FN <- 71
FP <- 3024
TN <- 4958

# Total
# A matriz de confus√£o usa apenas as linhas onde existe predi√ß√£o v√°lida
# E algumas linhas do teste ficaram com probabilidade = NA
Total <- TP + FN + FP + TN
nrow(teste)

# Acur√°cia
Acuracia <- (TP + TN) / Total
Acuracia

# Sensibilidade (Recall)
Sensibilidade <- TP / (TP + FN)
Sensibilidade

# Especificidade
Especificidade <- TN / (TN + FP)
Especificidade

# Precis√£o (PPV)
Precisao <- TP / (TP + FP)
Precisao


###############################################################
# SESS√ÉO 17 ‚Äî Estrair os coeficientes do MODELO DE REGRESS√ÉO
###############################################################
# logit(ùëù)=  ùõΩ0+ùõΩ1ùëã1+ùõΩ2ùëã2+‚Ä¶

summary(modelo)
coef(modelo)

# obter a f√≥rmula j√° formatada pelo R
formula(modelo)

# obter a equa√ß√£o completa em formato matem√°tico
library(equatiomatic)
extract_eq(modelo, use_coefs = TRUE)



# PAREI AQUI#
###############################################################
# SESS√ÉO 18 ‚Äî √Årvore de Decis√£o CHAID
# Usamos as mesmas vari√°veis finais do modelo de regress√£o,
# exceto:
# - CHAID n√£o aceita vari√°veis num√©ricas cont√≠nuas ‚Üí precisam ser factor
# - CHAID n√£o aceita vari√°veis com leakage
# - CHAID n√£o aceita vari√°veis com NA
# - CHAID n√£o usa vari√°veis descartadas por IV ou neg√≥cio
###############################################################

dataIV   # Apenas para consulta da for√ßa preditiva das vari√°veis

# Vari√°veis usadas no modelo de regress√£o:
# glm(Gravemente_feridos_Mortos ~    
#                 Periodo+
#                 Automovel+Bicicleta+
#                 Caminhao_bin+Moto_bin+Onibus_bin+Outros_bin+Utilitario_bin+
#                 Km_cat,

# Garantir que TODAS as vari√°veis explicativas usadas no CHAID
# estejam como factor (CHAID exige vari√°veis categ√≥ricas)
vars_para_factor <- c(
  "Periodo", "Automovel","Bicicleta","Caminhao_bin","Moto_bin",
  "Onibus_bin","Outros_bin","Utilitario_bin","Km_cat"
)

treino[vars_para_factor] <- lapply(treino[vars_para_factor], as.factor)
teste[vars_para_factor]  <- lapply(teste[vars_para_factor], as.factor)

# Garantir que a vari√°vel TARGET esteja como factor
# (CHAID n√£o funciona com target num√©rica)
treino$Gravemente_feridos_Mortos <- as.factor(treino$Gravemente_feridos_Mortos)
teste$Gravemente_feridos_Mortos  <- as.factor(teste$Gravemente_feridos_Mortos)

library(CHAID) 
library(dplyr)

# Controle da √°rvore: maxheight limita profundidade para evitar overfitting
# Controla quantos n√≠veis de splits a √°rvore pode ter
controle <- chaid_control(maxheight = 4)

# Ajuste da √°rvore CHAID usando exatamente as vari√°veis finais do modelo
arvore_4niveis <- chaid(
  Gravemente_feridos_Mortos ~
    Periodo +
    Automovel +
    Bicicleta +
    Caminhao_bin +
    Moto_bin +
    Onibus_bin +
    Outros_bin +
    Utilitario_bin +
    Km_cat,
  data = treino,
  control = controle
)

# Plot da √°rvore (visualiza√ß√£o padr√£o e uniforme)
plot(arvore_4niveis, uniform = TRUE, compress = TRUE, gp = gpar(cex = 0.6))


###############################################################
# SESS√ÉO 19 ‚Äî Probabilidades e n√≥s da √°rvore
###############################################################

# Identifica o n√∫mero do n√≥ terminal para cada observa√ß√£o do TREINO
# Isso permite analisar quais perfis caem em cada n√≥
treino$no <- predict(arvore_4niveis, treino, type = "node")


# Identificar "n√≥s"
with(treino, table(Periodo[treino$no == 28]))
with(treino, table(Periodo[treino$no == 29]))


# Frequ√™ncia de observa√ß√µes por n√≥
table(treino$no)

# Tabela cruzada: n√≥ x target
# cro_rpct mostra propor√ß√µes por linha/coluna (√≥timo para entender risco por n√≥)
cro_rpct(treino$no, treino$Gravemente_feridos_Mortos)

# Probabilidade prevista pelo CHAID para a classe "1"
# predict(..., type="p") retorna uma matriz com P(0) e P(1)
treino$prob <- predict(arvore_4niveis, treino, type = "p")[,2]

# Alternativa: salvar as duas probabilidades separadamente
probs <- as.data.frame(predict(arvore_4niveis, newdata = treino, type = "p"))
names(probs) <- c("P_0", "P_1")

# Anexa as probabilidades ao dataset de treino
treino <- cbind(treino, probs)

# Probabilidade geral da classe 1 no conjunto de treino
# (serve como cutoff baseado na taxa base)
prob_geral <- sum(treino$Gravemente_feridos_Mortos == "1") / nrow(treino)
prob_geral

# Classifica√ß√£o bin√°ria usando o cutoff = probabilidade geral
treino$predito_arvore <- ifelse(treino$prob >= prob_geral, "1", "0")

# Matriz de confus√£o: real x predito
cro(treino$Gravemente_feridos_Mortos, treino$predito_arvore)

# ‚úî Verdadeiros Negativos (0 ‚Üí 0): 23.652
# Muito bom ‚Äî a √°rvore acerta a maioria dos casos seguros.
# 
# ‚úî Verdadeiros Positivos (1 ‚Üí 1): 659
# Bom ‚Äî considerando que a classe 1 √© rara (3,35%).
# 
# ‚ùå Falsos Negativos (1 ‚Üí 0): 453
# Normal ‚Äî com cutoff baixo, sempre haver√° FN.
# 
# ‚ùå Falsos Positivos (0 ‚Üí 1): 8.448
# Tamb√©m normal ‚Äî CHAID tende a ser agressivo quando o cutoff √© baixo.


###############################################################
# SESS√ÉO 19 ‚Äî Avalia√ß√£o da √°rvore na base de teste
###############################################################


# 0. Forma de avaliar, quando separamos Treino e Teste √© comun para vari√°veis continuas
# Terem valores que aparecem em Treino mas n√£o em teste, e vice versa, 
# ent√£o abaixo temos um c√≥digo para testar em caso de erro, onde o erro informa a vari√°ve.
# verificar quais n√≠veis existem em cada base
# levels(treino$Bicicleta)
# levels(factor(teste$Bicicleta))
# Ou
# setdiff(unique(teste$Bicicleta), levels(treino$Bicicleta))


# 1. Alinhar n√≠veis do teste com os n√≠veis do treino
# Cada vari√°vel do teste passa a ter exatamente os mesmos n√≠veis do treino.  
# Qualquer n√≠vel "novo" em teste vira NA.  
for(v in vars_para_factor){
  teste[[v]] <- factor(teste[[v]], levels = levels(treino[[v]]))
}

# 2. Gerar probabilidades da √°rvore
teste$prob_arvore <- predict(arvore_4niveis, teste, type = "p")[,2]

# 3. Criar predi√ß√£o bin√°ria usando o cutoff prob_geral
teste$predito_arvore <- ifelse(teste$prob_arvore >= prob_geral, "1", "0")

# 4. Matriz de confus√£o
cro(teste$Gravemente_feridos_Mortos, teste$predito_arvore)

# 5. Interpreta√ß√£o dos quatro quadrantes

# ‚úî Verdadeiros Negativos (0 ‚Üí 0): 5851
# A √°rvore acerta a grande maioria dos casos seguros.
# Isso √© esperado, j√° que a classe 0 domina o dataset.
# 
# Interpreta√ß√£o:  
#   O modelo √© muito bom em identificar acidentes n√£o graves.
# 
# ‚úî Verdadeiros Positivos (1 ‚Üí 1): 201
# Esses s√£o os casos em que o modelo acertou acidentes graves.
# 
# Interpreta√ß√£o:  
#   Mesmo com classe rara (~3%), o modelo conseguiu capturar 201 casos graves corretamente.
# 
# ‚ùå Falsos Negativos (1 ‚Üí 0): 121
# Casos graves que o modelo classificou como n√£o graves.
# 
# Interpreta√ß√£o:  
#   Isso √© normal ‚Äî acidentes graves s√£o raros e dif√≠ceis de prever.
# Mas ainda assim, 121 FN √© um n√∫mero relativamente baixo.
# 
# ‚ùå Falsos Positivos (0 ‚Üí 1): 2131
# Casos n√£o graves que o modelo classificou como graves.
# 
# Interpreta√ß√£o:  
#   O modelo est√° agressivo, marcando muitos casos como risco alto.
# Isso √© t√≠pico quando o cutoff √© baixo (como o seu prob_geral).


# Conclus√£o
# A √°rvore est√° funcionando bem para um problema com classe rara.
# Ela √© conservadora: prefere errar para o lado de alertar risco (FP) do que deixar passar acidentes graves (FN).
# 
# Isso √© perfeito para aplica√ß√µes de seguran√ßa vi√°ria.



###############################################################
# SESS√ÉO 20 ‚Äî Conclus√µes Finais
###############################################################

# h) Qual modelo, dentre √°rvore de decis√£o e regress√£o log√≠stica, voc√™ recomenda?

# A regress√£o log√≠stica apresentou melhor desempenho geral, com m√©tricas mais equilibradas
# entre sensibilidade e especificidade. √â um modelo mais est√°vel, com menor quantidade de
# falsos positivos e melhor adequa√ß√£o para uso operacional.

# A √°rvore CHAID, por outro lado, apresentou maior sensibilidade, identificando mais casos
# graves, mas ao custo de muitos falsos positivos. Sua principal vantagem √© a interpretabilidade:
# regras claras, n√≥s bem definidos e perfis de risco facilmente comunic√°veis.

# Conclus√£o:
# - Regress√£o Log√≠stica ‚Üí melhor para previs√£o e uso operacional.
# - √Årvore CHAID ‚Üí melhor para interpreta√ß√£o, explica√ß√£o e entendimento dos padr√µes.
# Os modelos s√£o complementares: log√≠stica para prever, √°rvore para entender.


###############################################################
# SE√á√ÉO 21: RESUMO GERAL DO PROJETO
# Baseline Model Artifact  do Projeto de MLOps
# Data/Hora do registro:  
#   10/02/2026 ‚Äî 17:12 (Hor√°rio de Bras√≠lia)
###############################################################

# 1. Prepara√ß√£o da base
# - Importa√ß√£o, limpeza e transforma√ß√£o em data.frame.
# - An√°lise explorat√≥ria univariada.
# - Identifica√ß√£o da distribui√ß√£o da vari√°vel-alvo (~3,3% de casos graves).

# 2. Cria√ß√£o e tratamento das vari√°veis
# - Categoriza√ß√µes importantes (Automovel, Km).
# - Cria√ß√£o de vari√°veis bin√°rias (Onibus_bin, Caminhao_bin, etc.).
# - Convers√£o de vari√°veis categ√≥ricas para fator.

# 3. Sele√ß√£o de vari√°veis (IV)
# - C√°lculo do Information Value.
# - Remo√ß√£o de vari√°veis fracas ou sem varia√ß√£o.
# - Reten√ß√£o apenas das vari√°veis com poder explicativo relevante.

# 4. Divis√£o da base
# - Separa√ß√£o em treino (80%) e teste (20%).
# - Garantia de avalia√ß√£o realista e sem overfitting.

# 5. Regress√£o Log√≠stica
# - Ajuste do modelo com vari√°veis selecionadas.
# - Avalia√ß√£o de estabilidade (KS e AUC satisfat√≥rios).
# - Modelo final robusto e equilibrado.

# 6. Ponto de corte da Regress√£o
# - Cutoff escolhido: 0.0318.
# - Gera√ß√£o de predi√ß√µes bin√°rias e matriz de confus√£o.

# 7. Desempenho da Regress√£o (Teste)
# - Acur√°cia ‚âà 68,6%
# - Especificidade ‚âà 68,7%
# - Sensibilidade ‚âà 66,9%
# - Taxa de convers√£o ‚âà 7%

# 8. √Årvore de Decis√£o (CHAID)
# - Ajuste com vari√°veis categ√≥ricas.
# - Obten√ß√£o de n√≥s, regras e probabilidades por n√≥.
# - Probabilidade individual = probabilidade do n√≥.

# 9. Predi√ß√£o da √Årvore
# - Cutoff utilizado: probabilidade geral da carteira (~3,27%).
# - Gera√ß√£o de predi√ß√µes bin√°rias e matriz de confus√£o.

# 10. Desempenho da √Årvore (Teste) ‚Äî ATUALIZADO
# Matriz de confus√£o:
#                 Predito
#                 0      1
# Real 0        5851   2131
# Real 1         121    201
#
# - Acur√°cia: 72,8%
# - Especificidade: 73,3%
# - Sensibilidade: 62,4%
# - Taxa de convers√£o: 201 / (201 + 2131) ‚âà 8,6%
#
# A √°rvore √© mais agressiva, gerando muitos falsos positivos, mas captura boa parte dos casos graves.

# 11. Conclus√£o dos modelos
# - Regress√£o Log√≠stica: melhor desempenho geral, mais equilibrada, menos falsos positivos.
# - √Årvore CHAID: melhor interpretabilidade, regras claras, maior sensibilidade.
# - Modelos s√£o complementares: log√≠stica para previs√£o, √°rvore para entender perfis de risco.
