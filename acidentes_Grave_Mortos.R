###############################################################
# SESS√ÉO 1 ‚Äî Configura√ß√£o inicial e bibliotecas
###############################################################

setwd("G:\\Meu Drive\\predicao-acidentes")
# working directory

#Bibliotecas
library(dplyr)
library(readxl)
library(expss)
library(Information) 
library(arules)
library(smbinning)
library(HH)
library(InformationValue) 
library(scorecard)
library(partykit)
library(CHAID)
library(gtools)
library(expss)
library(devtools)
library(Hmisc)


#install.packages("devtools")
#devtools::install_github("cran/InformationValue")


###############################################################
# SESS√ÉO 1.1 ‚Äî Importa√ß√£o da base e prepara√ß√£o inicial
###############################################################

# ******************************************
# METODOLOGIA INICIAL PARA MONTAR O MODELO #
# ******************************************

library(readxl)
options(scipen=999)

# Conectar o R diretamente ao Excel
# data <- read_excel("dados.xlsx",sheet="Plan1") 
# data<-as.data.frame(data)


# Conectar o R diretamente ao SQL Server
#install.packages("odbc")
#install.packages("DBI")
library(DBI)
library(odbc)

# Conectar
conex_SQL <- dbConnect(odbc(),
                 Driver = "SQL Server",
                 Server = "PAULO",
                 Database = "TCC_FIA_2",
                 Trusted_Connection = "True")

# Testar conex√£o
dbGetQuery(conex_SQL, "
    SELECT TABLE_NAME 
    FROM INFORMATION_SCHEMA.TABLES 
    WHERE TABLE_SCHEMA = 'dbo'
")

# Desconectar
# dbDisconnect(conex_SQL) 

# Puxar a tabela do SQL e salvar no objeto data -- 67.127 registros
data <- dbGetQuery(conex_SQL, "
    SELECT *
    FROM dbo.base_acidentes_BR116_SP
")


# EXPORTAR O .CSV, origem SQL SERVER para BACKUP Silver
# Avalair se precisa sobrepor. Se houver altera√ß√£o no SQL, exportar novamente.
# write.csv(data, "data/silver/data.csv", row.names = FALSE)

# rm(data)

# Validar "data" origem SQL SERVER

nrow(data)
# 67127

# Adicionar Chave para validar inexistencia de duplicidades
# A chave deve acompanhar o pipeline at√© o split treino/teste
data <- data %>%
  dplyr::mutate(
    Chave = paste0(
      Concessionaria, "_",
      Trecho, "_",
      Num_Ocorrencia, "_",
      DataRef
    )
  )


###############################################
# 2. Padronizando as vari√°veis
# IDENTIFICADORES (n√£o entram no modelo)
###############################################

summary(data)

for (col in names(data)) print(col)
rm(col)

vars_id <- c(
  "Chave"   # identificador √∫nico do acidente
)

vars_tempo <- ("DataRef")

###############################################
# 2.1 VARI√ÅVEIS EXPLICATIVAS (X)
###############################################

# 2.1.1 Vari√°veis categ√≥ricas explicativas
vars_categoricas <- c(
  "Concessionaria",
  "Periodo",
  "Trecho",
  "Pista",
  "SentidoPadrao"
)

# 2.2.2 Vari√°veis num√©ricas explicativas (contagens)
vars_numericas <- c(
  "KmDecimal",
  "Automovel", "Bicicleta", "Caminhao", "Moto", "Onibus", "Outros", "Utilitario",
  "Ilesos", "Levemente_feridos", "Moderadamente_feridos",
  "Gravemente_feridos", "Mortos"
)

# 2.1.3 Vari√°veis bin√°rias explicativas (0/1)
vars_binarias <- c(
  "Automovel_bin", "Bicicleta_bin", "Caminhao_bin", "Moto_bin",
  "Onibus_bin", "Outros_bin", "Utilitario_bin",
  "Ilesos_bin", "Levemente_feridos_bin", "Moderadamente_feridos_bin",
  "Gravemente_feridos_bin", "Mortos_bin"
)


###############################################
# 2.2 POSS√çVEIS TARGETS (Y)
###############################################

# Estudo univariado, pontual
summary(data$TipoDeOcorrenciaPadrao)
cro(data$TipoDeOcorrenciaPadrao)

vars_target <- c(
  "TipoDeOcorrenciaPadrao",     # tipo de ocorr√™ncia (multiclasse)
  "Vitimas",                   # acidente teve v√≠timas (qualquer gravidade)
  "Gravemente_feridos_Mortos" # acidente grave (feridos graves ou mortos)
)

###############################################
# 2.3 TRATAMENTO DE VALORES VAZIOS
#    "" ‚Üí NA (decis√£o metodol√≥gica documentada)
# regress√£o log√≠stica n√£o aceita strings vazias
# √°rvores de decis√£o tratam vazio como categoria v√°lida, o que distorce tudo
# modelos preditivos ficam enviesados
# m√©tricas ficam erradas
# vari√°veis bin√°rias ficam quebradas
# Transformar vazios em NA √© obrigat√≥rio antes de seguir.
###############################################

# Avalia√ß√£o
colSums(is.na(data))
colSums(data == "")

# Substituir todos os vazios por NA
data[data == ""] <- NA

# Teste, para ver os NA reais.
colSums(is.na(data))

###############################################
# 2.4 CONVERS√ÉO DE TIPOS
###############################################

# 2.4.1 Converter vari√°veis num√©ricas
data[vars_numericas] <- lapply(data[vars_numericas], as.numeric)

# 2.4.2 Converter vari√°veis bin√°rias (0/1)
data[vars_binarias] <- lapply(data[vars_binarias], as.numeric)

# 2.4.3 Converter vari√°veis categ√≥ricas
data[vars_categoricas] <- lapply(data[vars_categoricas], as.factor)

# TipoDeOcorrenciaPadrao √© categ√≥rico (multiclasse)
data$TipoDeOcorrenciaPadrao <- as.factor(data$TipoDeOcorrenciaPadrao)

# 2.4.4 Converter data
data$DataRef <- as.Date(data$DataRef)
# ou
data[vars_tempo] <- lapply(data[vars_tempo], as.Date)

# 2.4.5 Converter targets
# Vitimas e Gravemente_feridos_Mortos s√£o bin√°rios
data$Vitimas <- as.numeric(data$Vitimas)
data$Gravemente_feridos_Mortos <- as.numeric(data$Gravemente_feridos_Mortos)


###############################################################
# SESS√ÉO 3 ‚Äî Avalia√ß√£o das TARGETS
# a target define o problema
###############################################################
str(data[vars_target]) 

cro(data$Vitimas)
cro_cpct(data$Vitimas)

cro(data$Gravemente_feridos_Mortos)
cro_cpct(data$Gravemente_feridos_Mortos)

cro(data$TipoDeOcorrenciaPadrao)
cro_cpct(data$TipoDeOcorrenciaPadrao)


# Vitimas √© ampla demais e mistura leve, moderado, grave e morte.
# TipoDeOcorrenciaPadrao s√≥ separa ‚Äúcom v√≠tima‚Äù e ‚Äúsem v√≠tima‚Äù, n√£o mede severidade.
# Gravemente_feridos_Mortos foca exatamente nos casos severos e representa 5,2% dos acidentes, refletindo melhor a realidade que queremos modelar.
#
# Conclus√£o: a target mais coerente e robusta para prever severidade √© Gravemente_feridos_Mortos.

vars_target <- setdiff(vars_target, "Vitimas")
vars_target <- setdiff(vars_target, "TipoDeOcorrenciaPadrao")
#
vars_target
str(data[vars_target]) 
# TARGET ESCOLHIDA
# Gravemente_feridos_Mortos 

###############################################################
# SESS√ÉO 4 ‚Äî An√°lise Explorat√≥ria Univariada (AED) e Bivariada
# Em an√°lise univariada e bivariada ‚Üí manter NA √© o certo
# objetivo: entender o fen√¥meno # Aqui NA √© informa√ß√£o
###############################################################

summary(data)

library(skimr)
skim (data)

names(data)

#Quantitativa
cro(data$Automovel) # o cro() oculta os NA por padr√£o.

# Tabela de frequencias
for (vars_numericas_analise in vars_numericas) {
  cat("\n\n==============================\n")
  cat("Frequ√™ncia de:", vars_numericas_analise, "\n")
  cat("==============================\n")
  print(table(data[[vars_numericas_analise]], useNA = "ifany"))
}


#Qualitativas / Categ√≥ricas

str(data[vars_categoricas])

cro_cpct(data$Concessionaria) # Desbalanceamento extremo O modelo n√£o aprende nada sobre a categoria minorit√°ria, por isso n√£o vamos usar no modelo
cro_cpct(data$Trecho) # O Trecho √© extremamente desbalanceado e, portanto, n√£o tem poder explicativo para o modelo.

vars_categoricas <- setdiff(vars_categoricas, "Concessionaria") # removido, mas mantido na base original para efeito de controle visual do dashboard
vars_categoricas <- setdiff(vars_categoricas, "Trecho") # removido

cro_cpct(data$Pista) # Como filtramos da base original apenas a BR‚Äë116/SP, o campo perdeu variabilidade
vars_categoricas <- setdiff(vars_categoricas, "Pista")

cro_cpct(data$SentidoPadrao) # O campo n√£o √© confi√°vel, mesmo ap√≥s tratamento continua (50/50).
vars_categoricas <- setdiff(vars_categoricas, "SentidoPadrao")

cro_cpct(data$Periodo) # tem distribui√ß√£o saud√°vel ou seja Variabilidade boa, N√£o √© colinear

#Bin√°rias
str(data[vars_binarias])

cro_cpct(data$Automovel_bin) # Boa, tem variabilidade

cro_cpct(data$Bicicleta_bin) # Ruim, Vari√°vel extremamente rara, Quase n√£o aparece na base
vars_binarias <- setdiff(vars_binarias, "Bicicleta_bin")

cro_cpct(data$Caminhao_bin) # Boa, tem variabilidade

cro_cpct(data$Moto_bin) # Boa, tem variabilidade

cro_cpct(data$Onibus_bin) # ‚â• 5% ‚Üí vari√°vel aceit√°vel, n√£o √© rara demais  

cro_cpct(data$Outros_bin) # Boa, tem variabilidade

cro_cpct(data$Utilitario_bin) # ‚â• 5% ‚Üí vari√°vel aceit√°vel, n√£o √© rara demais 

cro_cpct(data$Ilesos_bin) # ‚â• 5% ‚Üí vari√°vel aceit√°vel, n√£o √© rara demais 

cro_cpct(data$Levemente_feridos_bin) # Boa, tem variabilidade
vars_binarias <- setdiff(vars_binarias, "Levemente_feridos_bin") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o

cro_cpct(data$Moderadamente_feridos_bin) # Boa, tem variabilidade
vars_binarias <- setdiff(vars_binarias, "Moderadamente_feridos_bin") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o

cro_cpct(data$Gravemente_feridos_bin) # Fraca e usei para criar uma possivel target,n√£o deve entrar como preditora
vars_binarias <- setdiff(vars_binarias, "Gravemente_feridos_bin") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o

cro_cpct(data$Mortos_bin) # Fraca e usei para criar uma possivel target,n√£o deve entrar como preditora
vars_binarias <- setdiff(vars_binarias, "Mortos_bin") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o

vars_binarias

###############################################################
# SESS√ÉO 5 ‚Äî Categoriza√ß√£o de vari√°veis num√©ricas
# An√°lise Explorat√≥ria Univariada (AED) e Bivariada
###############################################################
str(data[vars_numericas]) 

str(data$Automovel)
summary(data$Automovel)

# Discretiza√ß√£o de Variavel com NA, 
qs_Automovel <- quantile(data$Automovel, probs = seq(0, 1, 0.25), na.rm = TRUE)
qs_Automovel <- unique(qs_Automovel)  # evita quantis repetidos
data$Automovel_cat <- cut(data$Automovel, breaks = qs_Automovel, include.lowest = TRUE)
rm(qs_Automovel)

sum(is.na(data$Automovel))
cro_cpct(data$Automovel_cat)
table(data$Automovel, data$Automovel_cat)
table(data$Automovel_cat, data$Gravemente_feridos_Mortos)

table(data$Automovel, data$Gravemente_feridos_Mortos)

sum(is.na(data$Automovel))
sum(is.na(data$Automovel_cat))

# Automovel √© uma vari√°vel num√©rica com informa√ß√£o rica.
# Automovel_cat destr√≥i granularidade

# Removendo variaveis que respondem como Target ou possuem rela√ß√£o direta com a Target escolhida.
str(data[vars_numericas]) 

vars_numericas <- setdiff(vars_numericas, "Ilesos") # Remove tamb√©m por que tem mais haver com target do que com explica√ß√£o
vars_numericas <- setdiff(vars_numericas, "Levemente_feridos")
vars_numericas <- setdiff(vars_numericas, "Moderadamente_feridos")
vars_numericas <- setdiff(vars_numericas, "Gravemente_feridos")
vars_numericas <- setdiff(vars_numericas, "Mortos")

# Avaliando demais vari√°veis numericas
str(data[vars_numericas]) 

# Distribui√ß√£o regular - vamos estudar no modelo - Removemos a vers√£o bin, vamos manter esta
table(data$Bicicleta, data$Gravemente_feridos_Mortos)

# Boa distribui√ß√£o, vamos manter esta
table(data$Caminhao, data$Gravemente_feridos_Mortos)

# Boa distribui√ß√£o, vamos manter esta
table(data$Moto, data$Gravemente_feridos_Mortos)

# Distribui√ß√£o regular - vamos estudar no modelo, vamos manter esta
table(data$Onibus, data$Gravemente_feridos_Mortos)

# Boa distribui√ß√£o, vamos manter esta
table(data$Outros, data$Gravemente_feridos_Mortos)

# N√£o muito Boa distribui√ß√£o, vamos manter esta para testar adiante
table(data$Utilitario, data$Gravemente_feridos_Mortos)

###############################################################
# SESS√ÉO 6 ‚Äî Optimal Binning : binning supervisionado
# binning supervisionado s√≥ para vari√°veis num√©ricas cont√≠nuas
# At√© aproximadamente 10 valores distintos (decimal ou inteiro)
###############################################################
str(data[vars_numericas]) 

library(smbinning)


# Para analise individual
KmDecimal_optbin<-smbinning(df=data,y="Gravemente_feridos_Mortos",x="KmDecimal",p=0.05) 
KmDecimal_optbin
KmDecimal_optbin$iv
KmDecimal_optbin$ivtable  
#
# Adicionando na base
data<-smbinning.gen(data,KmDecimal_optbin, chrname="KmDecimal_optbin_cat")

# CRIANDO uma nova variavel binning, n√£o ficamos coerentes com a realidade
# O que seria de utilidade prever Y at√© ante de X Km e ap√≥s de X Km, neste caso 97 Km
sum(is.na(data$KmDecimal_optbin_cat))
table(data$KmDecimal_optbin_cat, data$Gravemente_feridos_Mortos)
cro_cpct(data$KmDecimal_optbin_cat)
summary(data$KmDecimal)


# KmDecimal √© uma vari√°vel espacial, n√£o uma vari√°vel preditiva comum
summary(data$KmDecimal)
table(data$KmDecimal, data$Gravemente_feridos_Mortos)

# O nome t√©cnico desta opera√ß√£o √© Binning Manual
#### Arbitrei em 11 faixas para ficar mais pr√≥ximo da realidade ############
# A categoria (200,250] tinha 34,1% dos casos ‚Äî um monstr√£o desbalanceado.
# Agora, (200,225] ‚Üí 25,7% e (225,250] ‚Üí 8,4%, melhora a sensibilidade da regress√£o e da √°rvore e evita que uma categoria gigante ‚Äúengula‚Äù o efeito das outras
data$Km_cat <- cut(
  data$KmDecimal,
  breaks = c(0, 50, 100, 150, 200, 225, 250, 300, 350, 400, 450, 500, 600),
  include.lowest = TRUE
)
table(data$Km_cat, data$Gravemente_feridos_Mortos)
cro_cpct(data$Km_cat)
summary(data$Km_cat)

# DE 0 a 250 km concentra praticamente 80% dos acidentes # A rodovia √© ‚Äúdensa‚Äù at√© 250 km e ‚Äúrala‚Äù depois disso.
# Criar mais faixas abaixo de 250 km e manter faixas maiores acima disso.
data$Km_cat <- cut(
  data$KmDecimal,
  breaks = c(0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 300, 400, 500, 600),
  include.lowest = TRUE
)
# A probabilidade de 1 sobre 0 nessa faixa  "(200,225] 10442 515" √© similar √†s faixas vizinhas, A faixa √© grande, mas est√°vel
cro_cpct(data$Km_cat)
table(data$Km_cat, data$Gravemente_feridos_Mortos)
summary(data$Km_cat)



vars_categoricas <- c(vars_categoricas, "Km_cat")
vars_categoricas



###############################################################
# SESS√ÉO 7 ‚Äî Cria√ß√£o de vari√°veis derivadas
###############################################################
dim(data)
head(data)
str(data)
nrow(data)



data$Onibus_Caminhao_Bin <- ifelse(data$Onibus_bin==1 | data$Caminhao_bin == 1, 1, 0)
table(data$Onibus_Caminhao_Bin, data$Gravemente_feridos_Mortos)
cro_cpct(data$Onibus_Caminhao_Bin)
summary(data$Onibus_Caminhao_Bin)

vars_binarias <- c(vars_binarias, "Onibus_Caminhao_Bin")
vars_binarias

###############################################################
# SESS√ÉO 8 ‚Äî Convers√£o de vari√°veis para modelagem
# Transformar vari√°veis que s√£o categorias (e n√£o n√∫meros cont√≠nuos) em fatores, para que:
# a regress√£o log√≠stica trate como categorias, a CHAID funcione corretamente, o R n√£o interprete n√∫meros como valores cont√≠nuos
###############################################################

str(data)
library(dplyr)

# Transformar todas as vari√°veis categ√≥ricas em factor
data[vars_categoricas] <- lapply(data[vars_categoricas], as.factor)

# Transformar todas as vari√°veis bin√°rias em factor
data[vars_binarias] <- lapply(data[vars_binarias], as.factor)

# Vari√°veis num√©ricas (revis√£o)
data[vars_numericas] <- lapply(data[vars_numericas], as.numeric)


###############################################################
# SESS√ÉO 8.1 ‚Äî Transformas TARGET em factor 
# (regress√£o aceita target n√∫merico), mas vamos simplificar e garantir quando factor
# Transformamos o target em fator para que o modelo trate como vari√°vel categ√≥rica (0 e 1)
###############################################################

# Transformar a target em factor
data[vars_target] <- lapply(data[vars_target], as.factor)
# OU
data$Gravemente_feridos_Mortos <- as.factor(data$Gravemente_feridos_Mortos)

# Definimos o n√≠vel "0" como refer√™ncia, garantindo que o modelo estime P(Y = 1),
# ou seja, a probabilidade de ocorrer um acidente grave ou com morte
data$Gravemente_feridos_Mortos <- relevel(data$Gravemente_feridos_Mortos, ref = "0")
#Validar o relevel
levels(data$Gravemente_feridos_Mortos)
# Retornar -> [1] "0" "1"
# ‚Äú0‚Äù √© o n√≠vel de refer√™ncia
# ‚Äú1‚Äù √© o evento modelado


# ---------------------------------------------------------------
# Quando usar a target como NUM√âRICA (0/1) vs FACTOR
#
# M√©todos que exigem target NUM√âRICA (0/1):
# - IV / WOE
# - Regress√£o log√≠stica
# - XGBoost / LightGBM (bin√°rio)
# - M√©tricas de performance (AUC, KS, Lift, LogLoss, Sensibilidade, etc.)
#
# M√©todos que exigem target FACTOR:
# - √Årvores de decis√£o (rpart, C5.0, party)
# - Random Forest (classifica√ß√£o)
# - SVM / kNN / Naive Bayes
#
# Resumo:
# Use target NUM√âRICA para c√°lculos estat√≠sticos e modelos baseados em probabilidade.
# Use target FACTOR para modelos de classifica√ß√£o baseados em classes.
# ---------------------------------------------------------------


###############################################################
# SE√á√ÉO 9 ‚Äî Information Value (IV)
# CRIAR base para MODELO
# -------------------------------------------------------------
# Tabela de Interpreta√ß√£o do Information Value (IV)
#
# IV < 0.02        -> Sem poder preditivo
# 0.02 ‚Äì 0.10      -> Baixo poder preditivo
# 0.10 ‚Äì 0.30      -> M√©dio poder preditivo
# 0.30 ‚Äì 0.50      -> Forte poder preditivo
# IV > 0.50        -> Suspeito (pode indicar leakage)
# -------------------------------------------------------------
###############################################################

library(Information)

vars_modelagem <- c(
  vars_tempo,
  vars_numericas,
  vars_categoricas,
  vars_binarias,
  vars_target, # TARGET √öNICA
  vars_id # A CHAVE √öNICA deve acompanhar o pipeline at√© o split treino/teste
)

###############################################################
# CRIAR O DATA FRAME: base para inicio de modelagem
base <- data[, vars_modelagem]
###############################################################

# ‚ö†Ô∏è IMPORTANTE ‚Äî O que voc√™ N√ÉO deve fazer aqui
# Voc√™ N√ÉO deve:
# remover a chave
# remover DataRef ainda
# remover identificadores
# remover vari√°veis antes de calcular IV
# Tudo isso s√≥ acontece depois que a base est√° √≠ntegra.


# Removendo registro quando target = NA
# O target tem valores NA na base
sum(is.na(base$Gravemente_feridos_Mortos))/nrow(base)
# 36,9% da base est√° com o target NA
nrow(base)-sum(is.na(base$Gravemente_feridos_Mortos))
# A base sem NA dever√° contar 42303 registros

# remover apenas os registros com NA no target
base <- base[!is.na(base$Gravemente_feridos_Mortos), ]
cro_cpct(base$Gravemente_feridos_Mortos)
summary(base$Gravemente_feridos_Mortos)
nrow(base)
# 5,25% t√™m v√≠tima grave e/ou morta
# Ou seja, seu target √© fortemente desbalanceado, o que √© absolutamente normal em modelos de severidade.


# Transformar a vari√°vel target bin√°ria 0/1 de factor para num√©rica,
# para aplicar c√°lculos (IV), regress√£o glm() e √°rvore CHAID etc.
base$Gravemente_feridos_Mortos <- as.numeric(as.character(base$Gravemente_feridos_Mortos))
class(base$Gravemente_feridos_Mortos)
cro_cpct(base$Gravemente_feridos_Mortos)

# base agora est√° pronta para modelagem supervisionada.
# Come√ßar avaliando IV

###############################################################
# INFORMATION VALUE
# somente depois disso come√ßamos a remover: 
# leakage 
# vari√°veis fracas 
# vari√°veis redundantes 
# vari√°veis suspeitas (IV > 0.50) 
# SEM NUNCA remover a chave.
###############################################################
IV <- create_infotables(data = base, y = "Gravemente_feridos_Mortos")
IV$Summary

# üëâ O pr√≥prio c√≥digo do IV Ignora a DataRef para o c√°lculo do IV  
# O pacote Information s√≥ calcula IV para:    
# num√©ricas cont√≠nuas; num√©ricas discretas e fatores com poucos n√≠veis: Datas n√£o entram
#
# üëâ O pr√≥prio c√≥digo do IV Ignora a chave para o c√°lculo do IV  
# üëâ Mas N√ÉO remove a chave da sua base; üëâ Apenas n√£o calcula IV para ela
# A chave continua na base assim evita duplicados artificiais

# Variable         IV
# 4             Caminhao 2.44493864
# 12        Caminhao_bin 2.44493864
# 18 Onibus_Caminhao_Bin 2.30202564
# 3            Bicicleta 0.33812091
# 9              Periodo 0.27043833
# 5                 Moto 0.25010714
# 13            Moto_bin 0.25010714
# 7               Outros 0.23618959
# 15          Outros_bin 0.23618959
# 2            Automovel 0.19111147
# 6               Onibus 0.16749755
# 14          Onibus_bin 0.16749755
# 8           Utilitario 0.15257725
# 16      Utilitario_bin 0.15257725
# 17          Ilesos_bin 0.12392162
# 11       Automovel_bin 0.09476693
# 10              Km_cat 0.05366293
# 1            KmDecimal 0.03429499



# Remover leakage (derivadas do target)
# Remover vari√°veis que s√£o efeitos do acidente, n√£o causas.
# Vari√°veis de leakage devem ser removidas SEMPRE, independentemente do IV
# O IV N√ÉO √© influenciado por leakage. Voc√™ pode remover leakage ANTES ou DEPOIS ‚Äî o resultado do IV n√£o muda.
base$Ilesos_bin               <- NULL # S√≥ restava esta ser removida, as outras j√° haviam sido removidas anterioremente
base$Levemente_feridos_bin    <- NULL
base$Moderadamente_feridos_bin<- NULL
base$Gravemente_feridos_bin   <- NULL
base$Mortos_bin               <- NULL
#
#
base$Ilesos_bin         <- NULL
vars_binarias <- vars_binarias[vars_binarias != "Ilesos_bin"]
vars_binarias


# Remover duplicatas de informa√ß√£o MESMO IV: vers√£o num√©rica e bin√°ria (com seguran√ßa)
# A regra √©:
# üëâ Manter a vers√£o num√©rica  
# üëâ Remover a vers√£o bin√°ria equivalente
base$Caminhao_bin   <- NULL
vars_binarias <- vars_binarias[vars_binarias != "Caminhao_bin"]
base$Moto_bin       <- NULL
vars_binarias <- vars_binarias[vars_binarias != "Moto_bin"]
base$Outros_bin     <- NULL
vars_binarias <- vars_binarias[vars_binarias != "Outros_bin"]
base$Utilitario_bin <- NULL
vars_binarias <- vars_binarias[vars_binarias != "Utilitario_bin"]
base$Onibus_bin     <- NULL
vars_binarias <- vars_binarias[vars_binarias != "Onibus_bin"]


# Remover vari√°veis fracas (IV < 0.10)
# Automovel IV de 0.19111147, explica melhor o negocio e √© numerica serve tanto para regress√£o quanto para a arvore
# Automovel tem somente 13 valores de 0 at√© 12
# Mantemos Automovel para o modelo ter sentido teorico para o neg√≥cio na pr√°tica
table(base$Automovel, base$Gravemente_feridos_Mortos)
base$Automovel_bin      <- NULL   # 0.09476693
vars_binarias <- vars_binarias[vars_binarias != "Automovel_bin"]

# Remover vari√°veis fracas (IV < 0.10)
base$KmDecimal <- NULL # IV = 0.03429499
vars_numericas <- vars_numericas[vars_numericas != "KmDecimal"]
#
# Mantemos Km_cat por regra de neg√≥cio: para o modelo ter sentido teorico para o neg√≥cio na pr√°tica

# Remover vari√°veis suspeitas (IV > 0.50)
base$Onibus_Caminhao_Bin <- NULL
vars_binarias <- vars_binarias[vars_binarias != "Onibus_Caminhao_Bin"] # IV 2.30202564
# Mantemos as varaiveis numericas, Caminhao e Onibus derivantes de Onibus_Caminhao_Bin


# CRIAR VARIAVEIS PERIODICAS
# Criar M√™s (01 a 12)
base$Mes <- format(base$DataRef, "%m")

# Criar Dia da Semana
base$DiaSemana <- weekdays(base$DataRef)

# Padronizar nomes (Ajuda no CHAID e regress√£o)
base$DiaSemana <- factor(base$DiaSemana,
                         levels = c("segunda-feira","ter√ßa-feira","quarta-feira",
                                    "quinta-feira","sexta-feira","s√°bado","domingo"))


# Avaliar IV
IV <- create_infotables(data = base, y = "Gravemente_feridos_Mortos")
IV$Summary


# Remover vari√°veis temporais fracas e sem inclus√£o no IV por regra
# Excluir variaveis periodicas que nao tiveram bom IV e DataRef
# Ter certeza de que elas n√£o s√£o necess√°rias para o Supabase ou para auditoria.
base$DataRef   <- NULL
vars_tempo <- vars_tempo[vars_tempo != "DataRef"]
base$Mes     <- NULL            # IV de 0.03835127
base$DiaSemana      <- NULL     # IV de 0.02131159


# Avaliar IV
IV <- create_infotables(data = base, y = "Gravemente_feridos_Mortos")
IV$Summary
# Tabela IV
dataIV <- IV$Summary
dataIV$Classif_IV <- ifelse(dataIV$IV <= 0.02, "Fraquissimo",
                            ifelse(dataIV$IV <= 0.1 ,"Fraco",
                                   ifelse(dataIV$IV <= 0.3 ,"M√©dia",
                                          ifelse(dataIV$IV <= 0.5 ,"Forte",
                                                 "Suspeita"))))
dataIV

# Validar que a chave continua na base
"Chave" %in% names(base)
# TRUE

# Revis√£o da organiza√ß√£o das variaveis features
names(base)
vars_numericas
vars_categoricas
vars_binarias
vars_target
vars_id


###############################################################
# SESS√ÉO 10 ‚Äî Organiza√ß√£o da ordena√ß√£o final das vari√°veis
# N√£o foi necess√°rio
###############################################################

# names(base)
# base <- base[, c("Periodo",
#                  "Automovel",
#                  "Caminhao_bin", "Moto_bin", "Onibus_bin", "Utilitario_bin",
#                  "Bicicleta_bin", "Outros_bin",
#                  "Km_cat",
#                  "Gravemente_feridos_Mortos")]
# names(base)
# str(base)


###############################################################
# SESS√ÉO 11 ‚Äî Divis√£o Treino/Teste
# Sempre avaliar Tratar NAs nas vari√°veis do modelo, verificar se antecipa nesta etapa.
# Para modelagem ‚Üí remover NA apenas nas vari√°veis do modelo √© o certo
# objetivo: ajustar um modelo matem√°tico; NA atrapalha
###############################################################

# Verificar NAs no treino e teste
colSums(is.na(base))

names(base)
# [1] "Automovel"                 "Bicicleta"                 "Caminhao"                  "Moto"                     
# [5] "Onibus"                    "Outros"                    "Utilitario"                "Periodo"                  
# [9] "Km_cat"                    "Gravemente_feridos_Mortos" "Chave"  

# Criar a lista de vari√°veis que devem estar sem NA
# Inclui todas as features + target.
# N√£o inclui a Chave (correto: ela n√£o precisa ser crit√©rio de remo√ß√£o de NA para o modelo).
vars_modelo_Sem_NA <- c( "Automovel", "Bicicleta", "Caminhao", "Moto", 
                         "Onibus", "Outros", "Utilitario", "Periodo", 
                         "Km_cat", "Gravemente_feridos_Mortos" )

###############################################################
# Remover linhas com NA apenas nas vari√°veis usadas no modelo. 
# A CHAVE permanece na base, garantindo que N√ÉO haja duplicidade inflada.
base_limpa <- base[complete.cases(base[vars_modelo_Sem_NA]), ]
names(base_limpa)
nrow(base_limpa)
# 41516
# Cai de 42.303 para 41.516 registros porque removemos "NA"
###############################################################

# EXPORTADO EM 12/02/2026 O .CSV, base_limpa para simular produ√ß√£o MLOps
# write.csv(base_limpa, "data/prepared/base_limpa_v1.csv", row.names = FALSE)


# Fixamos a semente para garantir reprodutibilidade.
# Assim, sempre que rodarmos o c√≥digo, a mesma amostra ser√° selecionada.
set.seed(42)

# Selecionamos aleatoriamente 80% das linhas da base_limpa para compor o conjunto de treino.
amostra <- sort(sample(nrow(base_limpa), nrow(base_limpa) * 0.80))

# TREINO
# Conjunto de treino: usado para ajustar (treinar) os modelos.
treino <- base_limpa[amostra, ]
# TESTE
# Conjunto de teste: usado para avaliar o desempenho do modelo em dados novos.
teste <- base_limpa[-amostra, ]


###############################################################
# SESS√ÉO 12 ‚Äî Regress√£o Log√≠stica
###############################################################

dataIV # Origem base; que deu origem a base_limpa (Sem features com "NA") que deu origem as bases treino e teste

names(treino)

# Aplicar modelagem
modelo <- glm(Gravemente_feridos_Mortos ~  
                Automovel+Bicicleta+Caminhao+Moto+
                Onibus+Outros+Utilitario+Periodo+
                Km_cat,
              family=binomial(link='logit'),
              data=treino)
summary(modelo)
# AIC Akaike Information Criterion / Crit√©rio de Informa√ß√£o de Akaike
# Mede o equil√≠brio entre o qu√£o bem o modelo se ajusta aos dados (qualidade do ajuste) e o quanto ele √© simples (penaliza modelos com muitas vari√°veis)
# AIC DO MODELO: 8973.5
# AIC menor ‚Üí modelo melhor
# AIC maior ‚Üí modelo pior

# VARIAVEIS EM ALERTA:

### Km_cat
# Variavel de qualidade do entendimento do neg√≥cio
# IV Fraco 0.05366293
# o modelo precisa explicar risco por dist√¢ncia ‚Üí manter. porque se nao se torna o modelo sem sentido pr√°tico


# p-valor alto > 0.01
# Caminhao p-valor 0.4886 e Onibus: 0.6255 Mas vamos manter, pois representa um tipo de ve√≠culo cr√≠tico na severidade.

# utiliatario p-valor 0.5847
# Testar Modelo Sem a variavel "Utilitario"
# Utilitario: remover, pois tem baixo impacto e n√£o √© essencial ao modelo.
modelo_2 <- glm(Gravemente_feridos_Mortos ~  
                Automovel+Bicicleta+Caminhao+Moto+
                Onibus+Outros+Periodo+
                Km_cat,
              family=binomial(link='logit'),
              data=treino)
summary(modelo_2)
# AIC modelo_2: 8971.8 <  AIC modelo: 8973.5
# p-valor de Caminhao e Onibus praticamente nao foram alterados.
## Vamos seguir com o modelo inicial com todas as varaiveis.

# Frequ√™ncia da vari√°vel
# Se for rara ‚Üí remover ou agrupar.
#
# VIF (colinearidade) - alto ‚Üí remover
#
# Impacto no desempenho (AIC/AUC)
# Se o modelo piora sem ela ‚Üí manter
# Se nada muda ‚Üí remover
#
# Na regress√£o log√≠stica 
# Avaliar Estimate (coeficiente) ‚Üí interpreta√ß√£o do efeito no risco

###############################################################
# SESS√ÉO 13 ‚Äî VIF
# VIF = Variance Inflation Factor  
# √â um indicador que mostra quanto a vari√¢ncia do coeficiente de uma vari√°vel est√° sendo inflada por causa da multicolinearidade.
# VIF mede se uma vari√°vel est√° ‚Äúbrigando‚Äù com outra dentro do modelo.
# VIF entre 1 e 2 Excelente, sem colinearidade
# VIF < 5 ‚Üí seguro
# VIF entre 5 e 10 ‚Üí aten√ß√£o
# VIF > 10 ‚Üí problema s√©rio
###############################################################


library(HH)
vif(modelo)

# O modelo est√° coerente com a realidade operacional
# Usar a coluna: GVIF^(1/(2*Df))
# Todos VIF excelentes: N√£o existe colinearidade relevante


###############################################################
# SESS√ÉO 14 ‚Äî Ajustamento do Modelo / Se necess√°rio
###############################################################


# Aplicar modelagem
# modelo <- glm(Gravemente_feridos_Mortos ~    
#                 Periodo+
#                 Automovel+Bicicleta+
#                 Caminhao_bin+Moto_bin+Onibus_bin+Outros_bin+
#                 Km_cat,
#               family=binomial(link='logit'),
#               data=treino)
# summary(modelo)
# Remove Utilitario_bin
# AIC DO MODELO: 9145.3
# AIC: 9145.3, manteve o mesmo valor - Utilitario_bin realmente n√£o contribu√≠a com nada
# O modelo ficou mais simples
# N√£o perdeu qualidade (AIC igual)


###############################################################
# SESS√ÉO 15 ‚Äî KS (Kolmogorov-Smirnov), AUC e ROC
# KS: 0.00‚Äì0.20 muito fraco; 0.20‚Äì0.30 fraco; 0.30‚Äì0.40 razo√°vel; 0.40‚Äì0.50 bom; >0.50 excelente.
# AUC: 0.50 aleat√≥rio; 0.50‚Äì0.60 fraco; 0.60‚Äì0.70 razo√°vel; 0.70‚Äì0.80 bom; 0.80‚Äì0.90 muito bom; >0.90 suspeito.
# ROC: Interpreta√ß√£o visual
# Curva pr√≥xima da diagonal = fraco; levemente acima = razo√°vel;
# bem arqueada = bom; muito arqueada = excelente; quase perfeita = suspeito (overfitting).

###############################################################

library(pROC)

# ADICIONAR O CAMPO DA PROBABILIDADE ao treino
treino$probabilidade = predict(modelo,treino, type = "response")

ks_stat(actuals=treino$Gravemente_feridos_Mortos, predictedScores=treino$probabilidade)
# 0.3296 KS razo√°vel, esperado assim devido ao target raro; modelo est√°vel.

roc_obj <- pROC::roc(treino$Gravemente_feridos_Mortos, treino$probabilidade)
pROC::auc(roc_obj)
# Area under the curve: 0.7309 AUC bom

plot(roc_obj, col = "blue", lwd = 2)
# Devido o AUC, A curva ROC deve estar bem arqueada, mas n√£o perfeita.

###############################################################
# At√© aqui tivemos um bom treino, vamos validar em teste
###############################################################

# ADICIONAR O CAMPO DA PROBABILIDADE ao teste
teste$probabilidade = predict(modelo,teste, type = "response")

ks_stat(actuals=teste$Gravemente_feridos_Mortos, predictedScores=teste$probabilidade)
# 0.395 razo√°vel, esperado assim devido ao target raro; modelo est√°vel.

roc_obj_teste <- pROC::roc(teste$Gravemente_feridos_Mortos, teste$probabilidade)
pROC::auc(roc_obj_teste)
# Area under the curve: 0.7492 bom
# Desempenho consistente, condizente com o de treino e sem overfitting.

plot(roc_obj_teste, col = "blue", lwd = 2)
# Devido o AUC, A curva ROC deve estar bem arqueada, mas n√£o perfeita.
# Sobre o gr√°fico, Quanto mais a curva se aproxima do canto superior esquerdo, melhor
# Esse canto representa:Sensibilidade = 1, Falso positivo = 0 - Ou seja: modelo perfeito.


# Os resultados no teste est√£o totalmente coerentes com o que vimos no treino
# AUC: A diferen√ßa √© pequena ‚Üí n√£o h√° overfitting


###############################################################
# SESS√ÉO 16 ‚Äî Ponto de Corte
###############################################################

library(cutpointr)

# QUALIDADE (NA)
# AVALAIR/REVISAR SE EXISTE NA's TARGET da base (n√£o deve ter)
# NA acontece quando o predict() n√£o consegue calcular a probabilidade para algumas linhas do treino. 
# Porque Existem valores NA nas vari√°veis explicativas usadas no modelo.
colSums(is.na(treino[, c("probabilidade", "Gravemente_feridos_Mortos")]))
# probabilidade Gravemente_feridos_Mortos 
# 0                         0 
#
# Se NAs surgiram depois do modelo estar pronto, Isso n√£o afeta o modelo, s√≥ afeta a previs√£o dessas linhas.
# E o cutpointr n√£o aceita NA, por isso pode dar erro. Ent√£o deveremos Remover NAs agora, mas isso n√£o invalida nada. Depende o tamanho do estrago.
#
# Se necess√°rio Mant√©m somente as linhas onde nenhuma dessas duas colunas tem NA
# J√° eliminamos linhas com NA devido variaveis explicativas para criar a base de treino e teste
# treino2 <- treino[complete.cases(treino[, c("probabilidade", "Gravemente_feridos_Mortos")]), ]
# Confere se ainda existe NA
# colSums(is.na(treino2[, c("probabilidade", "Gravemente_feridos_Mortos")]))


# Equilibra sensibilidade e especificidade.
ponto <- cutpointr(treino, probabilidade, Gravemente_feridos_Mortos,
                   method = minimize_metric, metric = abs_d_sens_spec)
summary(ponto)
# Obter ponto de cort cuttoff abs_d_sens_spec: 0.0331.  Esse cutoff √© baixo, porque seu modelo gera probabilidades pequenas (target raro)
# optimal_cutpoint = 0.0331
# sensibilidade = 0.6628 # acerta 66.3% dos casos graves (sensibilidade).
# especificidade = 0.6632 
# Esse √© o cutoff mais adequado para modelos de severidade, onde FN √© caro.


# Accuracy engana quando a classe 1 √© rara. Descartado
ponto2 <- cutpointr(treino, probabilidade, Gravemente_feridos_Mortos,
                   method = maximize_metric, metric = accuracy)
summary(ponto2)
# Obter ponto de cort cuttoff: Inf    # accuracy d√° cutoff absurdo
# optimal_cutpoint = Inf   
# sensibilidade = 0
# especificidade = 1
# acc = 0.9665 # A Acur√°cia fica alta porque 97% dos casos s√£o 0.


# Cutoff pelo F1 (classe rara ‚Üí muito √∫til)
# Conservador N√£o recomendado para severidade.
ponto_f1 <- cutpointr(treino, probabilidade,Gravemente_feridos_Mortos,
                      method = maximize_metric, metric = F1_score)
summary(ponto_f1)
# optimal_cutpoint: 0.0896 Muito alto


# Cutoff pelo KS (maximiza separa√ß√£o)
# O cutoff que maximiza Youden √© o cutoff que maximiza o KS
ponto_ks <- cutpointr(treino, probabilidade, Gravemente_feridos_Mortos,
                      method = maximize_metric, metric = youden)
summary(ponto_ks)
# optimal_cutpoint:0.0321

# Qual cutoff √© o melhor para o seu modelo?
#   Seu problema √© severidade de acidentes, onde:   
#   FN = deixar de identificar um caso grave# 
#   FP = classificar como grave quando n√£o √©
# 
# Em modelos de severidade: ‚úî FN √© muito mais caro que FP
# 1¬∫ lugar: cuttoff youden: 0.0321
# 2¬∫ lugar: cuttoff abs_d_sens_spec: 0.0331
# Maior sensibilidade # Menor FN # Melhor separa√ß√£o estat√≠stica # Ideal para risco/severidade
ponto_definido <- 0.0321
ponto_definido


# PREVIS√ÉO BIN√ÅRIA BASEADA NO PONTO DE CORTE ANALISADO E DEFINIDO
teste$probb_cat <- ifelse(teste$probabilidade>ponto_definido,1,0)
# Gerar a matriz cruzada (confus√£o)
cro(teste$Gravemente_feridos_Mortos, teste$probb_cat)


###############################################################
# SESS√ÉO 16 ‚Äî M√©tricas de desempenho do TESTE
###############################################################

# matriz cruzada (confus√£o)
teste$Real <- teste$Gravemente_feridos_Mortos
teste$Predito <- teste$probb_cat
cro(teste$Real, teste$Predito)
# OU
cro(teste$Gravemente_feridos_Mortos, teste$probb_cat)

# Valores da matriz de confus√£o
#                  PREVIS√ÉO
#                  Negativo   Positivo
# REAL   Negativo    TN         FP
#        Positivo    FN         TP

TN <- 5209
FN <- 89
FP <- 2773
TP <- 233


# Total
# A matriz de confus√£o usa apenas as linhas onde existe predi√ß√£o v√°lida
# E algumas linhas do teste ficaram com probabilidade = NA
Total <- TP + FN + FP + TN
nrow(teste)
# 8304 linhas

# Acur√°cia
Acuracia <- (TP + TN) / Total
Acuracia
# 0.6553468

# Sensibilidade (Recall)
Sensibilidade <- TP / (TP + FN)
Sensibilidade
# 0.7236025

# Especificidade
Especificidade <- TN / (TN + FP)
Especificidade
# 0.6525933

# Precis√£o (PPV)
Precisao <- TP / (TP + FP)
Precisao
# 0.07751164

###############################################################
# SESS√ÉO 17 ‚Äî Estrair os coeficientes do MODELO DE REGRESS√ÉO
###############################################################
# logit(ùëù)=  ùõΩ0+ùõΩ1ùëã1+ùõΩ2ùëã2+‚Ä¶

summary(modelo)
coef(modelo)

# obter a f√≥rmula j√° formatada pelo R
formula(modelo)

# obter a equa√ß√£o completa em formato matem√°tico
library(equatiomatic)
extract_eq(modelo, use_coefs = TRUE)

###############################################################
# SESS√ÉO 18 ‚Äî √Årvore de Decis√£o CHAID
# Usamos as mesmas vari√°veis finais do modelo de regress√£o,
# exceto:
# - CHAID n√£o aceita vari√°veis num√©ricas cont√≠nuas ‚Üí precisam ser factor
# - CHAID n√£o aceita vari√°veis com leakage
# - CHAID n√£o aceita vari√°veis com NA
# - CHAID n√£o usa vari√°veis descartadas por IV ou neg√≥cio
###############################################################

dataIV   # Apenas para consulta da for√ßa preditiva das vari√°veis

# Variaveis do modelo de regresao:
# modelo <- glm(Gravemente_feridos_Mortos ~  
#                 Automovel+Bicicleta+Caminhao+Moto+
#                 Onibus+Outros+Utilitario+Periodo+
#                 Km_cat,

# Garantir que TODAS as vari√°veis explicativas usadas no CHAID
# estejam como factor (CHAID exige vari√°veis categ√≥ricas)
vars_para_factor <- c(
  "Automovel", "Bicicleta","Caminhao","Moto",
  "Onibus", "Outros","Utilitario","Periodo",
  "Km_cat"
)
vars_para_factor

treino[vars_para_factor] <- lapply(treino[vars_para_factor], as.factor)
teste[vars_para_factor]  <- lapply(teste[vars_para_factor], as.factor)

# Garantir que a vari√°vel TARGET esteja como factor
# (CHAID n√£o funciona com target num√©rica)
treino$Gravemente_feridos_Mortos <- as.factor(treino$Gravemente_feridos_Mortos)
teste$Gravemente_feridos_Mortos  <- as.factor(teste$Gravemente_feridos_Mortos)

library(CHAID) 
library(dplyr)

# Controle da √°rvore: maxheight limita profundidade para evitar overfitting
# Controla quantos n√≠veis de splits a √°rvore pode ter
controle <- chaid_control(maxheight = 4)

# Ajuste da √°rvore CHAID usando exatamente as vari√°veis finais do modelo
arvore_4niveis <- chaid(
  Gravemente_feridos_Mortos ~
    Automovel +
    Bicicleta +
    Caminhao +
    Moto +
    Onibus +
    Outros +
    Utilitario +
    Periodo +
    Km_cat,
  data = treino,
  control = controle
)

# Plot da √°rvore (visualiza√ß√£o padr√£o e uniforme)
plot(arvore_4niveis, uniform = TRUE, compress = TRUE, gp = gpar(cex = 0.6))

###############################################################
# SESS√ÉO 19 ‚Äî Probabilidades e n√≥s da √°rvore
###############################################################

# Identifica o n√∫mero do n√≥ terminal para cada observa√ß√£o do TREINO
# Isso permite analisar quais perfis caem em cada n√≥
treino$no <- predict(arvore_4niveis, treino, type = "node")


# Identificar "n√≥s" (Se n√£o estiver leg√≠vel no "plot")
with(treino, table(Periodo[treino$no == 28]))
with(treino, table(Periodo[treino$no == 29]))

# Frequ√™ncia de observa√ß√µes por n√≥
table(treino$no)

# Tabela cruzada: n√≥ x target
# cro_rpct mostra propor√ß√µes por linha/coluna (√≥timo para entender risco por n√≥)
cro_rpct(treino$no, treino$Gravemente_feridos_Mortos)

# Probabilidade prevista pelo CHAID para a classe "1"
# predict(..., type="p") retorna uma matriz com P(0) e P(1)
treino$prob_chaid <- predict(arvore_4niveis, treino, type = "p")[,2]

# Alternativa: salvar as duas probabilidades separadamente
probs <- as.data.frame(predict(arvore_4niveis, newdata = treino, type = "p"))
names(probs) <- c("P_0", "P_1")

# Anexa as probabilidades (0 | 1) ao dataset de treino
treino <- cbind(treino, probs)

# Probabilidade geral da classe 1 no conjunto de treino
# (serve como cutoff baseado na taxa base)
prob_geral <- sum(treino$Gravemente_feridos_Mortos == "1") / nrow(treino)
prob_geral
# 0.03348187  enquato o CuttOff da regres√£o foi 0.0321 (um pouco mais conservador)

# Classifica√ß√£o bin√°ria usando o cutoff = probabilidade geral
treino$predito_arvore <- ifelse(treino$prob_chaid >= prob_geral, "1", "0")

# Matriz de confus√£o: real x predito
cro(treino$Gravemente_feridos_Mortos, treino$predito_arvore)

# ‚úî Verdadeiros Negativos (0 ‚Üí 0): 22.4053
# Muito bom ‚Äî a √°rvore acerta a maioria dos casos seguros.
# 
# ‚úî Verdadeiros Positivos (1 ‚Üí 1): 655
# Bom ‚Äî considerando que a classe 1 √© rara (3,35%).
# 
# ‚ùå Falsos Negativos (1 ‚Üí 0): 457
# Normal ‚Äî com cutoff baixo, sempre haver√° FN.
# 
# ‚ùå Falsos Positivos (0 ‚Üí 1): 88047 
# Tamb√©m normal ‚Äî CHAID tende a ser agressivo quando o cutoff √© baixo.


###############################################################
# SESS√ÉO 19 ‚Äî Avalia√ß√£o da √°rvore na base de teste
###############################################################

# Quando separamos Treino e Teste √© comun para vari√°veis continuas
# Terem valores que aparecem em Treino mas n√£o em teste, e vice versa, 
# ent√£o abaixo temos um c√≥digo para testar em caso de erro, onde o erro informa a vari√°vel.
# verificar quais n√≠veis existem em cada base
# levels(treino$Bicicleta)
# levels(factor(teste$Bicicleta))
# Ou
# setdiff(unique(teste$Bicicleta), levels(treino$Bicicleta))

# 1. Alinhar n√≠veis do teste com os n√≠veis do treino
# Cada vari√°vel do teste passa a ter exatamente os mesmos n√≠veis do treino.  
# Qualquer n√≠vel "novo" em teste vira NA.  
for(v in vars_para_factor){
  teste[[v]] <- factor(teste[[v]], levels = levels(treino[[v]]))
}

# 2. Gerar probabilidades da √°rvore
teste$prob_arvore <- predict(arvore_4niveis, teste, type = "p")[,2]

# 3. Criar predi√ß√£o bin√°ria usando o cutoff prob_geral
teste$predito_arvore <- ifelse(teste$prob_arvore >= prob_geral, "1", "0")

# 4. Matriz de confus√£o
cro(teste$Gravemente_feridos_Mortos, teste$predito_arvore)

# 5. Interpreta√ß√£o dos quatro quadrantes
# Valores da matriz de confus√£o
#                  PREVIS√ÉO
#                  Negativo   Positivo
# REAL   Negativo    TN         FP
#        Positivo    FN         TP
#
# De 8.304 registros na base de teste
#
# ‚úî Verdadeiros Negativos (0 ‚Üí 0): 5969
# A √°rvore acerta a grande maioria dos casos seguros.
# Isso √© esperado, j√° que a classe 0 domina o dataset.# 
# Interpreta√ß√£o:  
#   O modelo √© muito bom em identificar acidentes n√£o graves.
# 
# ‚úî Verdadeiros Positivos (1 ‚Üí 1): 187
# Esses s√£o os casos em que o modelo acertou acidentes graves.# 
# Interpreta√ß√£o:  
#   Mesmo com classe rara (~3%), o modelo conseguiu capturar 187 casos graves corretamente.
# 
# ‚ùå Falsos Negativos (1 ‚Üí 0):  135
# Casos graves que o modelo classificou como n√£o graves.
# Interpreta√ß√£o:  
#   Isso √© normal ‚Äî acidentes graves s√£o raros e dif√≠ceis de prever.
# Mas ainda assim, 121 FN √© um n√∫mero relativamente baixo.
# 
# ‚ùå Falsos Positivos (0 ‚Üí 1):  2.013
# Casos n√£o graves que o modelo classificou como graves.
# 
# Interpreta√ß√£o:  
#   O modelo est√° agressivo, marcando muitos casos como risco alto.
# Isso √© t√≠pico quando o cutoff √© baixo (como o seu prob_geral).


# Conclus√£o
# A √°rvore est√° funcionando bem para um problema com classe rara.
# Ela √© conservadora: prefere errar para o lado de alertar risco (FP) do que deixar passar acidentes graves (FN).
# 
# Isso √© perfeito para aplica√ß√µes de seguran√ßa vi√°ria.


###############################################################
# SESS√ÉO 20 ‚Äî Conclus√µes Finais (ATUALIZADA)
###############################################################

# A seguir apresentamos a conclus√£o integrada dos dois modelos
# do baseline: Regress√£o Log√≠stica e √Årvore de Decis√£o CHAID.
# A an√°lise considera desempenho estat√≠stico, estabilidade,
# interpretabilidade e adequa√ß√£o operacional.

###############################################################
# 1. Regress√£o Log√≠stica ‚Äî Conclus√£o
###############################################################

# M√©tricas finais (TESTE):
# - AUC: 0.7492  ‚Üí bom
# - KS: 0.395    ‚Üí razo√°vel/bom para classe rara
# - Cutoff √≥timo (Youden): 0.0321
#
# Matriz de confus√£o (teste):
#   TN = 5209
#   FP = 2773
#   FN = 89
#   TP = 233
#
# M√©tricas derivadas:
# - Acur√°cia:      0.6553
# - Sensibilidade: 0.7236   (excelente para classe rara)
# - Especificidade:0.6526
# - Precis√£o:      0.0775   (esperado em classe rara)
#
# Conclus√£o t√©cnica:
# - Modelo est√°vel, sem overfitting.
# - Bom poder discriminativo (AUC ~0.75).
# - Equil√≠brio adequado entre sensibilidade e especificidade.
# - Baixa taxa de FN (muito importante em severidade).
#
# Conclus√£o operacional:
# - Melhor modelo para uso em produ√ß√£o.
# - Mais previs√≠vel, calibr√°vel e com menos falsos positivos.
# - Ideal para scoring cont√≠nuo e monitoramento em MLOps.

###############################################################
# 2. √Årvore de Decis√£o CHAID ‚Äî Conclus√£o
###############################################################

# Cutoff utilizado: probabilidade geral da carteira = 0.03348
#
# Matriz de confus√£o (teste):
#   TN = 5969
#   FP = 2013
#   FN = 135
#   TP = 187
#
# Interpreta√ß√£o:
# - A √°rvore captura mais casos graves (TP maior que a regress√£o).
# - Por√©m, gera muito mais falsos positivos.
# - Sens√≠vel ao cutoff e mais agressiva por natureza.
# - Excelente interpretabilidade: regras claras e n√≥s bem definidos.
#
# Conclus√£o t√©cnica:
# - √ötil para entendimento dos padr√µes de risco.
# - N√£o √© o melhor modelo para predi√ß√£o operacional.

###############################################################
# 3. Compara√ß√£o Final
###############################################################

# Regress√£o Log√≠stica:
# - Melhor AUC, melhor KS, mais equilibrada.
# - Menos falsos positivos.
# - Maior estabilidade entre treino e teste.
# - Melhor adequa√ß√£o para produ√ß√£o.

# √Årvore CHAID:
# - Maior sensibilidade (captura mais casos graves).
# - Muito mais falsos positivos.
# - Excelente interpretabilidade.
# - Melhor para explicar perfis de risco.

###############################################################
# 4. Recomenda√ß√£o Final
###############################################################

# ‚úî Regress√£o Log√≠stica ‚Üí Modelo recomendado para PRODU√á√ÉO
#   - Melhor equil√≠brio geral.
#   - Menos FP.
#   - Est√°vel, robusto e adequado para MLOps.

# ‚úî √Årvore CHAID ‚Üí Modelo recomendado para INTERPRETA√á√ÉO
#   - Regras claras.
#   - Perfis de risco facilmente comunic√°veis.
#   - Complementa a regress√£o na explica√ß√£o dos padr√µes.

# ‚úî Conclus√£o geral:
#   - Os modelos s√£o COMPLEMENTARES.
#   - Log√≠stica para prever.
#   - CHAID para entender.

###############################################################
# SE√á√ÉO 21: FIM
# Baseline Model Artifact  do Projeto de MLOps
# Data/Hora do registro: 12/02/2026 
###############################################################
